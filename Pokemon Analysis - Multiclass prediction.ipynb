{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0a3be7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0) # Set for testing purposes, please do not change!\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "\n",
    "# library to get dataloader\n",
    "from dataloaders import get_pkmn_dataloader,get_denormalization_transform\n",
    "\n",
    "# library to get loss functions\n",
    "from loss_functions import get_generator_loss_func,get_disc_loss_func,gradient_penalty,get_gradient\n",
    "\n",
    "# generators and discriminators\n",
    "from DCGeneratorCustom import DCGeneratorCustom\n",
    "from DCDiscriminatorCustom import DCDiscriminatorCustom\n",
    "from DCGeneratorStandard import DCGeneratorStandard\n",
    "from DCDiscriminatorStandard import DCDiscriminatorStandard\n",
    "from DCDiscriminatorStandardDropout import DCDiscriminatorStandardDropout\n",
    "from DiscriminatorPatchGAN import DiscriminatorPatchGAN\n",
    "\n",
    "from DCGeneratorConditional import DCGeneratorConditional\n",
    "from DCDiscriminatorConditional import DCDiscriminatorConditional\n",
    "from UNetArchitecture import UNet\n",
    "\n",
    "\n",
    "# for classification analysis\n",
    "from MultiClassConvNetStandardDropout import MultiClassConvNetStandardDropout\n",
    "\n",
    "# util methods\n",
    "from utils import get_noise\n",
    "\n",
    "# constants\n",
    "from pkmn_constants import PKMN_TYPES,CLASS_IDX_2_PKMN_TYPE,NUM_PKMN_TYPES\n",
    "\n",
    "# whether to use CPU/GPU (pass this along everywhere)\n",
    "device_str = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device_str)\n",
    "\n",
    "print(\"Using device: {}\".format(device_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a100e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "\n",
    "# if apply_denormalization is true, then we re-scale the images back \n",
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28), denorm_transform = None, use_uniform_transform = False):\n",
    "    '''\n",
    "    Function for visualizing images: Given a tensor of images, number of images, and\n",
    "    size per image, plots and prints the images in an uniform grid.\n",
    "    '''\n",
    "    \n",
    "    # We don't specifically need this since we are doing the denormalization ourself\n",
    "    \n",
    "    if denorm_transform is not None:\n",
    "      assert use_uniform_transform == False\n",
    "      image_tensor = denorm_transform(image_tensor)\n",
    "    if use_uniform_transform:\n",
    "      # cannot use both uniform and denorm transform together\n",
    "      assert denorm_transform == None\n",
    "      image_tensor = (image_tensor + 1) / 2 # scale from [-1, 1] to [0, 1] space\n",
    "    image_unflat = image_tensor.detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()\n",
    "\n",
    "def save_model(model, output_filename):\n",
    "  torch.save(model.state_dict(), output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730bbcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Define the dataloader ===\n",
    "\n",
    "jpg_directory = \"./pokemon_images_size=64_shiny=False__bg=WHITE_mainclass=True_groupclasses=True\" \n",
    "\n",
    "# Convert channels from [0, 1] to [-1, 1]\n",
    "channel_means, channel_stds = (0.5, 0.5, 0.5), (0.5,0.5,0.5)\n",
    "\n",
    "normal_transforms = transforms.Compose([\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(mean = channel_means, std = channel_stds)\n",
    "])\n",
    "\n",
    "# use random flip and normalization transform\n",
    "flip_transforms = transforms.Compose([\n",
    "  transforms.RandomHorizontalFlip(p=1.0),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(mean = channel_means, std = channel_stds)\n",
    "])\n",
    "\n",
    "# use random flip and normalization transform\n",
    "rotate_transforms = transforms.Compose([\n",
    "  transforms.RandomRotation(45), # rotate up to 45 degrees in each direction\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(mean = channel_means, std = channel_stds)\n",
    "])\n",
    "\n",
    "\n",
    "pkmn_data_normal = datasets.ImageFolder(root = jpg_directory,transform = normal_transforms)\n",
    "pkmn_data_flipped = datasets.ImageFolder(root = jpg_directory,transform = flip_transforms)\n",
    "pkmn_data_rotated = datasets.ImageFolder(root = jpg_directory,transform = rotate_transforms)\n",
    "\n",
    "\n",
    "final_dataset = ConcatDataset([pkmn_data_normal, pkmn_data_flipped, pkmn_data_rotated])\n",
    "\n",
    "train_frac = 0.8\n",
    "\n",
    "train_size = int(train_frac * len(final_dataset))\n",
    "test_size = len(final_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(final_dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "pkmn_dataloader_train = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                              batch_size=batch_size, \n",
    "                                              shuffle=True, \n",
    "                                              num_workers=1)\n",
    "\n",
    "pkmn_dataloader_val = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                              batch_size=batch_size, \n",
    "                                              shuffle=True, \n",
    "                                              num_workers=1)\n",
    "\n",
    "\n",
    "denorm_transform = get_denormalization_transform(channel_means,channel_stds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee0e07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_validation_accuracy(model, dataloader):\n",
    "  all_true_labels = []\n",
    "  all_preds = []\n",
    "  for real, true_labels in tqdm(dataloader):\n",
    "    # get the predictions. Shape (bs, num_classes)\n",
    "    model_logits = model(real)\n",
    "\n",
    "    model_preds = torch.argmax(model_logits, dim = 1)\n",
    "    \n",
    "    all_true_labels.extend(true_labels.numpy().tolist())\n",
    "    \n",
    "    #print(model_preds.shape)\n",
    "    all_preds.extend(model_preds.numpy().tolist())\n",
    "    \n",
    "  val_acc = accuracy_score(all_true_labels, all_preds)\n",
    "  return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e784feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= Define the basic hyper-parameters =====\n",
    "\n",
    "\n",
    "# training epochs\n",
    "n_epochs = 5\n",
    "\n",
    "# hidden dimensions\n",
    "hidden_dim = 32\n",
    "batch_size = 64\n",
    "\n",
    "num_classes = 13 # todo: change this if using different problem formulations\n",
    "\n",
    "periodic_saving = False\n",
    "# after how many epochs do you save the model?\n",
    "epoch_save_step = 5\n",
    "save_prefix = \"Pokemon_Discriminator_DC_multiclass_types\"\n",
    "\n",
    "lr = 1e-3\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "\n",
    "# how often to display chart\n",
    "display_step = 100\n",
    "\n",
    "\n",
    "# loss functions\n",
    "use_wgan_loss = False\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d8e9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkmn_dataloader = pkmn_dataloader_train\n",
    "\n",
    "test_img_size = 10\n",
    "\n",
    "# show a batch before and after denorm\n",
    "test_data_iter = iter(pkmn_dataloader)\n",
    "test_images, test_labels = next(test_data_iter)\n",
    "\n",
    "print(\"length of dataset (number of steps) is: {}, total size is: {}\".format(len(pkmn_dataloader), len(pkmn_dataloader)*batch_size))\n",
    "\n",
    "\n",
    "if show_preview:\n",
    "  show_tensor_images(test_images[0:test_img_size], num_images = test_size, size = (3,64,64), denorm_transform = None)\n",
    "  show_tensor_images(test_images[0:test_img_size], num_images = test_size, size = (3,64,64), denorm_transform = denorm_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a1243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the generator/discriminator and use them\n",
    "# layer initialization for Generator and Discriminator (for Conv2d and ConvTranpose2d)\n",
    "\n",
    "model = MultiClassConvNetStandardDropout(num_classes = num_classes, hidden_dim = hidden_dim).to(device) \n",
    "model_opt = torch.optim.Adam(model.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
    "\n",
    "print(\"Initializing the model with {} classes!\".format(num_classes))\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "model = model.apply(weights_init)\n",
    "\n",
    "# summarize the model and its parameters\n",
    "summary(model, [(3,64,64)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59280606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "cur_step = 0\n",
    "losses = []\n",
    "batch_accs = []\n",
    "val_accs = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Dataloader returns the (real_images, labels)\n",
    "    for real, true_labels in tqdm(pkmn_dataloader):\n",
    "        cur_batch_size = len(real)\n",
    "        real = real.to(device)\n",
    "        true_labels = true_labels.to(device)\n",
    "        \n",
    "        # zero out optimizer\n",
    "        model_opt.zero_grad()\n",
    "        \n",
    "        # get the predictions. Shape (bs, num_classes)\n",
    "        model_logits = model(real)\n",
    "                \n",
    "        model_preds = torch.argmax(model_logits, dim = 1)\n",
    "        \n",
    "        # y_true, y_pred\n",
    "        model_acc = accuracy_score(true_labels, model_preds)\n",
    "        batch_accs.append(model_acc)\n",
    "        \n",
    "        # compute the loss on a batch\n",
    "        ce_loss = loss_func(model_logits, true_labels)\n",
    "        \n",
    "        # record loss for graphing purposes\n",
    "        losses.append(ce_loss)\n",
    "        \n",
    "        # backprop\n",
    "        ce_loss.backward()\n",
    "        \n",
    "        # update optimizer\n",
    "        model_opt.step()\n",
    "        \n",
    "        ### Visualization code ###\n",
    "        if cur_step % display_step == 0 and cur_step > 0:\n",
    "            mean_loss = sum(losses[-display_step:]) / display_step\n",
    "            mean_acc = sum(batch_accs[-display_step:]) / display_step\n",
    "            print(f\"Step {cur_step}: Epoch: {epoch}: loss: {mean_loss} acc: {mean_acc}\")\n",
    "            step_bins = 20\n",
    "            \n",
    "            num_examples = (len(losses) // step_bins) * step_bins\n",
    "            plt.plot(\n",
    "                range(num_examples // step_bins), \n",
    "                torch.Tensor(losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                label=\"Loss\"\n",
    "            )\n",
    "            plt.plot(\n",
    "                range(num_examples // step_bins), \n",
    "                torch.Tensor(batch_accs[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                label=\"Val Acc\"\n",
    "            )                   \n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            \n",
    "            val_acc = compute_validation_accuracy(model, pkmn_dataloader_val)\n",
    "            val_accs.append(val_acc)\n",
    "            \n",
    "            print(\"Latest validation accuracy after {} epochs is: {}\".format(epoch, val_acc))\n",
    "        \n",
    "        # increase the current step (ie. one batch)\n",
    "        cur_step += 1\n",
    "        \n",
    "    if periodic_saving and epoch % epoch_save_step == 0:\n",
    "      outfile_name = \"{}_{}.pt\".format(save_prefix, cur_step)\n",
    "      print(\"===== Saving intermediate model with name {} ! ====\".format(outfile_name))\n",
    "      save_model(gen, outfile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f627c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "\n",
    "out_file = \"mutliclass_dcgan_prediction.pt\"\n",
    "  \n",
    "save_model(model, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce2ab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some utility for drawing distributions\n",
    "\n",
    "type_dict = {  \n",
    "    'Bug': 213,\n",
    "    'Dark': 58,\n",
    "    'Dragon': 61,\n",
    "    'Electric': 132,\n",
    "    'Fairy': 33,\n",
    "    'Fighting': 72,\n",
    "    'Fire': 141,\n",
    "    'Flying': 3,\n",
    "    'Ghost': 64,\n",
    "    'Grass': 211,\n",
    "    'Ground': 99,\n",
    "    'Ice': 65,\n",
    "    'Normal': 386,\n",
    "    'Poison': 106,\n",
    "    'Psychic': 264,\n",
    "    'Rock': 117,\n",
    "    'Steel': 57,\n",
    "    'Water': 380}\n",
    "\n",
    "types_and_counts = [ (k,v) for k,v in type_dict.items()]\n",
    "types = [x[0] for x in types_and_counts]\n",
    "counts = [x[1] for x in types_and_counts]\n",
    "\n",
    "print(types)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c1be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing random state for reproducibility\n",
    "np.random.seed(19680801)\n",
    "\n",
    "plt.rcdefaults()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Example data\n",
    "y_pos = np.arange(len(types))\n",
    "\n",
    "ax.barh(types, counts, align='center')\n",
    "ax.set_yticks(y_pos, labels=types)\n",
    "ax.invert_yaxis()  # labels read top-to-bottom\n",
    "ax.set_xlabel('Count')\n",
    "ax.set_title('Distribution of Pokemon By Type')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34ec40d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pkmn_types = 13\n",
    "  \n",
    "test_tensor = torch.rand((24, num_pkmn_types + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc3eab67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of source outputs is: torch.Size([24, 1])\n",
      "Shape of pkmn class outputs is: torch.Size([24, 13])\n"
     ]
    }
   ],
   "source": [
    "source_outputs = (test_tensor[:, 0]).view(24, 1)\n",
    "pkmn_class_outputs = test_tensor[:, 1:]\n",
    "\n",
    "print(\"shape of source outputs is: {}\".format(source_outputs.shape))\n",
    "print(\"Shape of pkmn class outputs is: {}\".format(pkmn_class_outputs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d2e67e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
