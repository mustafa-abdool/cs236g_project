{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0a3be7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0) # Set for testing purposes, please do not change!\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# library to get dataloader\n",
    "from dataloaders import get_pkmn_dataloader\n",
    "\n",
    "# library to get loss functions\n",
    "from loss_functions import get_generator_loss_func,get_disc_loss_func,gradient_penalty,get_gradient\n",
    "\n",
    "# generators and discriminators\n",
    "from DCGeneratorCustom import DCGeneratorCustom\n",
    "from DCDiscriminatorCustom import DCDiscriminatorCustom\n",
    "from DCGeneratorStandard import DCGeneratorStandard\n",
    "from DCDiscriminatorStandard import DCDiscriminatorStandard\n",
    "from DCDiscriminatorStandardDropout import DCDiscriminatorStandardDropout\n",
    "from DiscriminatorPatchGAN import DiscriminatorPatchGAN\n",
    "\n",
    "from DCGeneratorConditional import DCGeneratorConditional\n",
    "from DCDiscriminatorConditional import DCDiscriminatorConditional\n",
    "from UNetArchitecture import UNet\n",
    "\n",
    "\n",
    "# util methods\n",
    "from utils import get_noise\n",
    "\n",
    "# constants\n",
    "from pkmn_constants import PKMN_TYPES,CLASS_IDX_2_PKMN_TYPE,NUM_PKMN_TYPES\n",
    "\n",
    "# whether to use CPU/GPU (pass this along everywhere)\n",
    "device_str = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device_str)\n",
    "\n",
    "print(\"Using device: {}\".format(device_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a100e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.2\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "\n",
    "# if apply_denormalization is true, then we re-scale the images back \n",
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28), denorm_transform = None, use_uniform_transform = False):\n",
    "    '''\n",
    "    Function for visualizing images: Given a tensor of images, number of images, and\n",
    "    size per image, plots and prints the images in an uniform grid.\n",
    "    '''\n",
    "    \n",
    "    # We don't specifically need this since we are doing the denormalization ourself\n",
    "    \n",
    "    if denorm_transform is not None:\n",
    "      assert use_uniform_transform == False\n",
    "      image_tensor = denorm_transform(image_tensor)\n",
    "    if use_uniform_transform:\n",
    "      # cannot use both uniform and denorm transform together\n",
    "      assert denorm_transform == None\n",
    "      image_tensor = (image_tensor + 1) / 2 # scale from [-1, 1] to [0, 1] space\n",
    "    image_unflat = image_tensor.detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()\n",
    "\n",
    "def save_model(model, output_filename):\n",
    "  torch.save(model.state_dict(), output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed52153f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 96, 96]              32\n",
      "   FeatureMapBlock-2           [-1, 16, 96, 96]               0\n",
      "            Conv2d-3           [-1, 32, 96, 96]           4,640\n",
      "       BatchNorm2d-4           [-1, 32, 96, 96]              64\n",
      "           Dropout-5           [-1, 32, 96, 96]               0\n",
      "         LeakyReLU-6           [-1, 32, 96, 96]               0\n",
      "            Conv2d-7           [-1, 32, 96, 96]           9,248\n",
      "       BatchNorm2d-8           [-1, 32, 96, 96]              64\n",
      "           Dropout-9           [-1, 32, 96, 96]               0\n",
      "        LeakyReLU-10           [-1, 32, 96, 96]               0\n",
      "        MaxPool2d-11           [-1, 32, 48, 48]               0\n",
      " ContractingBlock-12           [-1, 32, 48, 48]               0\n",
      "           Conv2d-13           [-1, 64, 48, 48]          18,496\n",
      "      BatchNorm2d-14           [-1, 64, 48, 48]             128\n",
      "          Dropout-15           [-1, 64, 48, 48]               0\n",
      "        LeakyReLU-16           [-1, 64, 48, 48]               0\n",
      "           Conv2d-17           [-1, 64, 48, 48]          36,928\n",
      "      BatchNorm2d-18           [-1, 64, 48, 48]             128\n",
      "          Dropout-19           [-1, 64, 48, 48]               0\n",
      "        LeakyReLU-20           [-1, 64, 48, 48]               0\n",
      "        MaxPool2d-21           [-1, 64, 24, 24]               0\n",
      " ContractingBlock-22           [-1, 64, 24, 24]               0\n",
      "           Conv2d-23          [-1, 128, 24, 24]          73,856\n",
      "      BatchNorm2d-24          [-1, 128, 24, 24]             256\n",
      "          Dropout-25          [-1, 128, 24, 24]               0\n",
      "        LeakyReLU-26          [-1, 128, 24, 24]               0\n",
      "           Conv2d-27          [-1, 128, 24, 24]         147,584\n",
      "      BatchNorm2d-28          [-1, 128, 24, 24]             256\n",
      "          Dropout-29          [-1, 128, 24, 24]               0\n",
      "        LeakyReLU-30          [-1, 128, 24, 24]               0\n",
      "        MaxPool2d-31          [-1, 128, 12, 12]               0\n",
      " ContractingBlock-32          [-1, 128, 12, 12]               0\n",
      "           Conv2d-33          [-1, 256, 12, 12]         295,168\n",
      "      BatchNorm2d-34          [-1, 256, 12, 12]             512\n",
      "        LeakyReLU-35          [-1, 256, 12, 12]               0\n",
      "           Conv2d-36          [-1, 256, 12, 12]         590,080\n",
      "      BatchNorm2d-37          [-1, 256, 12, 12]             512\n",
      "        LeakyReLU-38          [-1, 256, 12, 12]               0\n",
      "        MaxPool2d-39            [-1, 256, 6, 6]               0\n",
      " ContractingBlock-40            [-1, 256, 6, 6]               0\n",
      "           Conv2d-41            [-1, 512, 6, 6]       1,180,160\n",
      "      BatchNorm2d-42            [-1, 512, 6, 6]           1,024\n",
      "        LeakyReLU-43            [-1, 512, 6, 6]               0\n",
      "           Conv2d-44            [-1, 512, 6, 6]       2,359,808\n",
      "      BatchNorm2d-45            [-1, 512, 6, 6]           1,024\n",
      "        LeakyReLU-46            [-1, 512, 6, 6]               0\n",
      "        MaxPool2d-47            [-1, 512, 3, 3]               0\n",
      " ContractingBlock-48            [-1, 512, 3, 3]               0\n",
      "           Conv2d-49           [-1, 1024, 3, 3]       4,719,616\n",
      "      BatchNorm2d-50           [-1, 1024, 3, 3]           2,048\n",
      "        LeakyReLU-51           [-1, 1024, 3, 3]               0\n",
      "           Conv2d-52           [-1, 1024, 3, 3]       9,438,208\n",
      "      BatchNorm2d-53           [-1, 1024, 3, 3]           2,048\n",
      "        LeakyReLU-54           [-1, 1024, 3, 3]               0\n",
      "        MaxPool2d-55           [-1, 1024, 1, 1]               0\n",
      " ContractingBlock-56           [-1, 1024, 1, 1]               0\n",
      "         Upsample-57           [-1, 1024, 2, 2]               0\n",
      "           Conv2d-58            [-1, 512, 1, 1]       2,097,664\n",
      "           Conv2d-59            [-1, 512, 1, 1]       4,719,104\n",
      "      BatchNorm2d-60            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-61            [-1, 512, 1, 1]               0\n",
      "           Conv2d-62            [-1, 512, 2, 2]       1,049,088\n",
      "      BatchNorm2d-63            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-64            [-1, 512, 2, 2]               0\n",
      "   ExpandingBlock-65            [-1, 512, 2, 2]               0\n",
      "         Upsample-66            [-1, 512, 4, 4]               0\n",
      "           Conv2d-67            [-1, 256, 3, 3]         524,544\n",
      "           Conv2d-68            [-1, 256, 3, 3]       1,179,904\n",
      "      BatchNorm2d-69            [-1, 256, 3, 3]             512\n",
      "             ReLU-70            [-1, 256, 3, 3]               0\n",
      "           Conv2d-71            [-1, 256, 4, 4]         262,400\n",
      "      BatchNorm2d-72            [-1, 256, 4, 4]             512\n",
      "             ReLU-73            [-1, 256, 4, 4]               0\n",
      "   ExpandingBlock-74            [-1, 256, 4, 4]               0\n",
      "         Upsample-75            [-1, 256, 8, 8]               0\n",
      "           Conv2d-76            [-1, 128, 7, 7]         131,200\n",
      "           Conv2d-77            [-1, 128, 7, 7]         295,040\n",
      "      BatchNorm2d-78            [-1, 128, 7, 7]             256\n",
      "             ReLU-79            [-1, 128, 7, 7]               0\n",
      "           Conv2d-80            [-1, 128, 8, 8]          65,664\n",
      "      BatchNorm2d-81            [-1, 128, 8, 8]             256\n",
      "             ReLU-82            [-1, 128, 8, 8]               0\n",
      "   ExpandingBlock-83            [-1, 128, 8, 8]               0\n",
      "         Upsample-84          [-1, 128, 16, 16]               0\n",
      "           Conv2d-85           [-1, 64, 15, 15]          32,832\n",
      "           Conv2d-86           [-1, 64, 15, 15]          73,792\n",
      "      BatchNorm2d-87           [-1, 64, 15, 15]             128\n",
      "             ReLU-88           [-1, 64, 15, 15]               0\n",
      "           Conv2d-89           [-1, 64, 16, 16]          16,448\n",
      "      BatchNorm2d-90           [-1, 64, 16, 16]             128\n",
      "             ReLU-91           [-1, 64, 16, 16]               0\n",
      "   ExpandingBlock-92           [-1, 64, 16, 16]               0\n",
      "         Upsample-93           [-1, 64, 32, 32]               0\n",
      "           Conv2d-94           [-1, 32, 31, 31]           8,224\n",
      "           Conv2d-95           [-1, 32, 31, 31]          18,464\n",
      "      BatchNorm2d-96           [-1, 32, 31, 31]              64\n",
      "             ReLU-97           [-1, 32, 31, 31]               0\n",
      "           Conv2d-98           [-1, 32, 32, 32]           4,128\n",
      "      BatchNorm2d-99           [-1, 32, 32, 32]              64\n",
      "            ReLU-100           [-1, 32, 32, 32]               0\n",
      "  ExpandingBlock-101           [-1, 32, 32, 32]               0\n",
      "        Upsample-102           [-1, 32, 64, 64]               0\n",
      "          Conv2d-103           [-1, 16, 63, 63]           2,064\n",
      "          Conv2d-104           [-1, 16, 63, 63]           4,624\n",
      "     BatchNorm2d-105           [-1, 16, 63, 63]              32\n",
      "            ReLU-106           [-1, 16, 63, 63]               0\n",
      "          Conv2d-107           [-1, 16, 64, 64]           1,040\n",
      "     BatchNorm2d-108           [-1, 16, 64, 64]              32\n",
      "            ReLU-109           [-1, 16, 64, 64]               0\n",
      "  ExpandingBlock-110           [-1, 16, 64, 64]               0\n",
      "          Conv2d-111            [-1, 3, 64, 64]              51\n",
      " FeatureMapBlock-112            [-1, 3, 64, 64]               0\n",
      " ConvTranspose2d-113            [-1, 3, 96, 96]           9,804\n",
      "            Tanh-114            [-1, 3, 96, 96]               0\n",
      "================================================================\n",
      "Total params: 29,381,999\n",
      "Trainable params: 29,381,999\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 49.01\n",
      "Params size (MB): 112.08\n",
      "Estimated Total Size (MB): 161.09\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# testing if we can create and summarize the Unet\n",
    "# Input is (bs, z_dim)\n",
    "# output is (3, 96, 96) image (difficult to change this!)\n",
    "\n",
    "# How would we extend this to a conditional input ?\n",
    "\n",
    "\n",
    "test_unet = UNet(input_channels = 1, output_channels = 3, hidden_channels = 16)\n",
    "\n",
    "test_unet(torch.ones(7, 32))\n",
    "\n",
    "summary(test_unet, [(1, 32)], device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e75bbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 96, 96]              32\n",
      "   FeatureMapBlock-2            [-1, 8, 96, 96]               0\n",
      "            Conv2d-3           [-1, 16, 96, 96]           1,168\n",
      "         LeakyReLU-4           [-1, 16, 96, 96]               0\n",
      "            Conv2d-5           [-1, 16, 96, 96]           2,320\n",
      "         LeakyReLU-6           [-1, 16, 96, 96]               0\n",
      "         MaxPool2d-7           [-1, 16, 48, 48]               0\n",
      "  ContractingBlock-8           [-1, 16, 48, 48]               0\n",
      "            Conv2d-9           [-1, 32, 48, 48]           4,640\n",
      "      BatchNorm2d-10           [-1, 32, 48, 48]              64\n",
      "        LeakyReLU-11           [-1, 32, 48, 48]               0\n",
      "           Conv2d-12           [-1, 32, 48, 48]           9,248\n",
      "      BatchNorm2d-13           [-1, 32, 48, 48]              64\n",
      "        LeakyReLU-14           [-1, 32, 48, 48]               0\n",
      "        MaxPool2d-15           [-1, 32, 24, 24]               0\n",
      " ContractingBlock-16           [-1, 32, 24, 24]               0\n",
      "           Conv2d-17           [-1, 64, 24, 24]          18,496\n",
      "      BatchNorm2d-18           [-1, 64, 24, 24]             128\n",
      "        LeakyReLU-19           [-1, 64, 24, 24]               0\n",
      "           Conv2d-20           [-1, 64, 24, 24]          36,928\n",
      "      BatchNorm2d-21           [-1, 64, 24, 24]             128\n",
      "        LeakyReLU-22           [-1, 64, 24, 24]               0\n",
      "        MaxPool2d-23           [-1, 64, 12, 12]               0\n",
      " ContractingBlock-24           [-1, 64, 12, 12]               0\n",
      "           Conv2d-25          [-1, 128, 12, 12]          73,856\n",
      "      BatchNorm2d-26          [-1, 128, 12, 12]             256\n",
      "        LeakyReLU-27          [-1, 128, 12, 12]               0\n",
      "           Conv2d-28          [-1, 128, 12, 12]         147,584\n",
      "      BatchNorm2d-29          [-1, 128, 12, 12]             256\n",
      "        LeakyReLU-30          [-1, 128, 12, 12]               0\n",
      "        MaxPool2d-31            [-1, 128, 6, 6]               0\n",
      " ContractingBlock-32            [-1, 128, 6, 6]               0\n",
      "           Conv2d-33              [-1, 1, 6, 6]             129\n",
      "================================================================\n",
      "Total params: 295,297\n",
      "Trainable params: 295,297\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 12.59\n",
      "Params size (MB): 1.13\n",
      "Estimated Total Size (MB): 13.82\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# What are the differences here?\n",
    "# PatchGan input is (3x96x96)\n",
    "# output is 6x6 patches if input dim is 96\n",
    "# output is 8x8 patches if input dim is 128\n",
    "# Basically, it's easy to change the shape of the input dimension image, we just create more patches\n",
    "\n",
    "test_patchgan = DiscriminatorPatchGAN(input_channels = 3)\n",
    "\n",
    "summary(test_patchgan, [(3, 96, 96)], device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e784feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= Define the basic hyper-parameters =====\n",
    "\n",
    "\n",
    "# training epochs\n",
    "n_epochs = 1\n",
    "\n",
    "# dimension of noise vector\n",
    "z_dim = 32\n",
    "# hidden dimensions\n",
    "hidden_dim_gen = 6\n",
    "hidden_dim_disc = 6\n",
    "disc_class_embed_size = 16\n",
    "batch_size = 32\n",
    "# how often to display images and debug info. Basically, the numerator is how many images you want to\n",
    "# process before showing some debug info\n",
    "display_step = int((4000 / batch_size))\n",
    "periodic_saving = False\n",
    "# after how many epochs do you save the model?\n",
    "epoch_save_step = 1\n",
    "save_prefix = \"experiment_10/test_patchgan\"\n",
    "imgs_to_display = 10\n",
    "\n",
    "print(\"Planning to display images every {} steps\".format(display_step))\n",
    "\n",
    "# other sources say 0.00275 works better...but the DCGAn paper used 0.0002 (ie. about 10-4 instead of 10-3)\n",
    "gen_lr = 0.0002 # 0.0002 works for both, but takes at least 10-15 epochs before anything interesting happens?\n",
    "disc_lr = 0.0002\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "disc_repeats = 1\n",
    "gen_repeats = 1\n",
    "\n",
    "# loss functions\n",
    "use_wgan_loss = False\n",
    "if use_wgan_loss:\n",
    "  gen_loss_func = get_generator_loss_func(\"wgan_gen_loss\")\n",
    "  disc_loss_func = get_disc_loss_func(\"wgan_disc_loss\")\n",
    "  c_lambda = 10\n",
    "else:\n",
    "  gen_loss_func = get_generator_loss_func(\"basic_gen_loss_with_logits\")\n",
    "  disc_loss_func = get_disc_loss_func(\"noisy_patchgan_disc_loss\")\n",
    "\n",
    "assert imgs_to_display <= batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d8e9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataloader, based on the appropriate batch size. \n",
    "\n",
    "show_preview = True\n",
    "dataloader_name = \"shiny_96_flip_rotate_jitter_rotate_custom_normalize\"\n",
    "pkmn_dataloader, denorm_transform = get_pkmn_dataloader(dataloader_name, batch_size)\n",
    "test_size = 10\n",
    "\n",
    "# show a batch before and after denorm\n",
    "test_data_iter = iter(pkmn_dataloader)\n",
    "test_images, test_labels = next(test_data_iter)\n",
    "\n",
    "print(\"length of dataset (number of steps) is: {}, total size is: {}\".format(len(pkmn_dataloader), len(pkmn_dataloader)*batch_size))\n",
    "\n",
    "if show_preview:\n",
    "  show_tensor_images(test_images[0:test_size], num_images = test_size, size = (3,64,64), denorm_transform = None)\n",
    "  show_tensor_images(test_images[0:test_size], num_images = test_size, size = (3,64,64), denorm_transform = denorm_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a1243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the generator/discriminator and use them\n",
    "# layer initialization for Generator and Discriminator (for Conv2d and ConvTranpose2d)\n",
    "\n",
    "gen = UNet(z_dim = z_dim, hidden_channels= hidden_dim_gen).to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=gen_lr, betas=(beta_1, beta_2))\n",
    "disc = DiscriminatorPatchGAN(hidden_channels = hidden_dim_disc).to(device) \n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=disc_lr, betas=(beta_1, beta_2))\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "gen = gen.apply(weights_init)\n",
    "disc = disc.apply(weights_init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59280606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "cur_step = 0\n",
    "generator_losses = []\n",
    "discriminator_losses = []\n",
    "discriminator_fake_preds = [] # median value of P(real) the discriminator predicts on the fake images (per batch)\n",
    "discriminator_real_preds = [] # median value of P(real) the discriminator predicts on the real images (per batch)\n",
    "simgoid_function = nn.Sigmoid()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Dataloader returns the (real_images, labels)\n",
    "    for real, true_labels in tqdm(pkmn_dataloader):\n",
    "        cur_batch_size = len(real)\n",
    "        real = real.to(device)\n",
    "        true_labels = true_labels.to(device)\n",
    "        \n",
    "        mean_iteration_discriminator_loss = 0\n",
    "        for _ in range(disc_repeats):\n",
    "            ### Update discriminator ###\n",
    "            disc_opt.zero_grad()\n",
    "            fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
    "            fake = gen(fake_noise)\n",
    "                        \n",
    "            disc_fake_pred = disc(fake.detach())\n",
    "            disc_real_pred = disc(real)\n",
    "\n",
    "            \n",
    "            if use_wgan_loss:\n",
    "              epsilon = torch.rand(len(real), 1, 1, 1, device=device, requires_grad=True)\n",
    "              gradient = get_gradient(disc, real, true_labels, fake.detach(), epsilon)\n",
    "              gp = gradient_penalty(gradient)\n",
    "              # how should we track these two relative losses ?\n",
    "              disc_loss = disc_loss_func(disc_fake_pred, disc_real_pred, gp, c_lambda)              \n",
    "\n",
    "            else:\n",
    "              # compute discriminator loss normally\n",
    "              disc_loss = disc_loss_func(disc_fake_pred, disc_real_pred, device)\n",
    "            \n",
    "            # Keep track of the average discriminator loss in this batch\n",
    "            mean_iteration_discriminator_loss += disc_loss.item() / disc_repeats\n",
    "            \n",
    "            # Update gradients\n",
    "            # when using WGAN, we have retain_graph = True, but it probably takes longer\n",
    "            disc_loss.backward(retain_graph=use_wgan_loss)\n",
    "            \n",
    "            # Update optimizer\n",
    "            disc_opt.step()\n",
    "            \n",
    "        discriminator_losses += [mean_iteration_discriminator_loss]\n",
    "        # notice this only takes the last one from the iteration (if you run the discriminator multiple times)\n",
    "        # use a Sigmoid here to go from logits back into the P(real) space\n",
    "        discriminator_fake_preds += [sigmoid_function(torch.mean(disc_fake_pred).detach())]\n",
    "        discriminator_real_preds += [sigmoid_function(torch.mean(disc_real_pred).detach())]\n",
    "\n",
    "        ### Update generator ###\n",
    "        mean_iteration_gen_loss = 0\n",
    "        for _ in range(gen_repeats):\n",
    "          gen_opt.zero_grad()\n",
    "          fake_noise_2 = get_noise(cur_batch_size, z_dim, device=device)\n",
    "          fake_2 = gen(fake_noise_2)\n",
    "          disc_fake_pred = disc(fake_2)\n",
    "\n",
    "          # compute gen loss\n",
    "          gen_loss = gen_loss_func(disc_fake_pred, device)\n",
    "          \n",
    "          mean_iteration_gen_loss += gen_loss.item() / gen_repeats\n",
    "          \n",
    "          gen_loss.backward()\n",
    "\n",
    "          # Update the weights\n",
    "          gen_opt.step()\n",
    "\n",
    "        # Keep track of the average generator loss\n",
    "        generator_losses += [mean_iteration_gen_loss]\n",
    "        \n",
    "        ### Visualization code ###\n",
    "        if cur_step % display_step == 0 and cur_step > 0:\n",
    "            gen_mean = sum(generator_losses[-display_step:]) / display_step\n",
    "            disc_mean = sum(discriminator_losses[-display_step:]) / display_step\n",
    "            # maybe print out the last values here ? To see how stable it is overtime ? These all seem to be very close to 0.5 / 1\n",
    "            disc_prediction_real = sum(discriminator_real_preds[-display_step:]) / display_step\n",
    "            disc_prediction_fake = sum(discriminator_fake_preds[-display_step:]) / display_step\n",
    "            print(f\"Step {cur_step}: Epoch: {epoch}: Generator loss: {gen_mean}, discriminator loss: {disc_mean} mean disc pred on real images: {disc_prediction_real}, fake images: {disc_prediction_fake}\")\n",
    "            show_tensor_images(fake[0:imgs_to_display], imgs_to_display, size = (3,64,64), denorm_transform = denorm_transform)\n",
    "            show_tensor_images(real[0:imgs_to_display], imgs_to_display, size = (3,64,64), denorm_transform = denorm_transform)\n",
    "            \n",
    "            ground_truth_types = [CLASS_IDX_2_PKMN_TYPE[class_idx] for class_idx in true_labels[0:imgs_to_display].cpu().numpy()]\n",
    "            print(\"Pokemon types we are trying to generate are: {} \\n    \\t \\t \\t \\t \\t {}\".format(ground_truth_types[0:5], ground_truth_types[5:]))\n",
    "            \n",
    "            step_bins = 20\n",
    "            \n",
    "            # todo: add proper labels to this plot\n",
    "            num_examples = (len(generator_losses) // step_bins) * step_bins\n",
    "            plt.plot(\n",
    "                range(num_examples // step_bins), \n",
    "                torch.Tensor(generator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                label=\"Generator Loss\"\n",
    "            )\n",
    "            plt.plot(\n",
    "                range(num_examples // step_bins), \n",
    "                torch.Tensor(discriminator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                label=\"discriminator Loss\"\n",
    "            )\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        \n",
    "        # increase the current step (ie. one batch)\n",
    "        cur_step += 1\n",
    "        \n",
    "    if periodic_saving and epoch % epoch_save_step == 0:\n",
    "      outfile_name = \"{}_{}.pt\".format(save_prefix, cur_step)\n",
    "      print(\"===== Saving intermediate model with name {} ! ====\".format(outfile_name))\n",
    "      save_model(gen, outfile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f627c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "\n",
    "out_file = \"second_gan_with_standard_dcgan_arch_after_149epochs.pt\"\n",
    "  \n",
    "save_model(gen, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da493fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model for inference and generate some random classes\n",
    "\n",
    "gen.load_state_dict(torch.load(\"{}\".format(out_file)))\n",
    "\n",
    "# Performing inference - actually, maybe I ran some other cell after this so it's not really well defined\n",
    "num_samples = 10\n",
    "\n",
    "sample_vector = get_noise(num_samples, z_dim, device)\n",
    "random_classes = torch.randint(low = 0, high = NUM_PKMN_TYPES, size = (num_samples,)).to(device)\n",
    "\n",
    "fake_images = gen(sample_vector, random_classes)\n",
    "\n",
    "output_size = gen.output_dim\n",
    "# + 0.9\n",
    "show_tensor_images(fake_images, num_images=num_samples, size=(1,256, 256), use_uniform_transform = True, denorm_transform = None)\n",
    "\n",
    "\n",
    "pkmn_classes = [CLASS_IDX_2_PKMN_TYPE[class_idx] for class_idx in random_classes.cpu().numpy()]\n",
    "print(\"Pokemon types we are trying to generate are: {} \\n    \\t \\t \\t \\t \\t {}\".format(pkmn_classes[0:5], pkmn_classes[5:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f9caf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples of a specific type from the model\n",
    "target_type = \"Fire\"\n",
    "class_idx = PKMN_TYPES.index(target_type)\n",
    "\n",
    "class_tiled = torch.from_numpy(np.array([class_idx] * num_samples))\n",
    "\n",
    "sample_vector = get_noise(num_samples, z_dim, device)\n",
    "classes = class_tiled.to(device)\n",
    "\n",
    "fake_images = gen(sample_vector, classes)\n",
    "\n",
    "output_size = gen.output_dim\n",
    "# + 0.9\n",
    "show_tensor_images(fake_images, num_images=num_samples, size=(1,256, 256), use_uniform_transform = True, denorm_transform = None)\n",
    "\n",
    "\n",
    "pkmn_classes = [CLASS_IDX_2_PKMN_TYPE[class_idx] for class_idx in classes.cpu().numpy()]\n",
    "print(\"Pokemon types we are trying to generate are: {} \\n    \\t \\t \\t \\t \\t {}\".format(pkmn_classes[0:5], pkmn_classes[5:]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
