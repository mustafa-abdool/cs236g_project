{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0a3be7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0) # Set for testing purposes, please do not change!\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# library to get dataloader\n",
    "from dataloaders import get_pkmn_dataloader\n",
    "\n",
    "# library to get loss functions\n",
    "from loss_functions import get_generator_loss_func,get_disc_loss_func,gradient_penalty,get_gradient\n",
    "\n",
    "# generators and discriminators\n",
    "from DCGeneratorCustom import DCGeneratorCustom\n",
    "from DCDiscriminatorCustom import DCDiscriminatorCustom\n",
    "from DCGeneratorStandard import DCGeneratorStandard\n",
    "from DCDiscriminatorStandard import DCDiscriminatorStandard\n",
    "from DCDiscriminatorStandardDropout import DCDiscriminatorStandardDropout\n",
    "from DiscriminatorPatchGAN import DiscriminatorPatchGAN,DiscriminatorPatchGANConditional\n",
    "from DCGeneratorConditionalLarge import DCGeneratorConditionalLarge\n",
    "\n",
    "from DCGeneratorConditional import DCGeneratorConditional\n",
    "from DCGeneratorConditionalLarge import DCGeneratorConditionalLarge\n",
    "from DCDiscriminatorConditional import DCDiscriminatorConditional\n",
    "from DCDiscriminatorConditionalLarge import DCDiscriminatorConditionalLarge\n",
    "from UNetArchitecture import UNet,UNetConditional,UNetConditionalImage\n",
    "\n",
    "# util methods\n",
    "from utils import get_noise,get_image_noise\n",
    "\n",
    "# constants\n",
    "from pkmn_constants import PKMN_TYPES,CLASS_IDX_2_PKMN_TYPE,NUM_PKMN_TYPES,REDUCED_PKMN_TYPES,CLASS_IDX_2_PKMN_TYPE_REDUCED\n",
    "\n",
    "# whether to use CPU/GPU (pass this along everywhere)\n",
    "device_str = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device_str)\n",
    "\n",
    "print(\"Using device: {}\".format(device_str))\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a100e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.2\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "\n",
    "# if apply_denormalization is true, then we re-scale the images back \n",
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28), denorm_transform = None, use_uniform_transform = False):\n",
    "    '''\n",
    "    Function for visualizing images: Given a tensor of images, number of images, and\n",
    "    size per image, plots and prints the images in an uniform grid.\n",
    "    '''\n",
    "    \n",
    "    # We don't specifically need this since we are doing the denormalization ourself\n",
    "    \n",
    "    if denorm_transform is not None:\n",
    "      assert use_uniform_transform == False\n",
    "      image_tensor = denorm_transform(image_tensor)\n",
    "    if use_uniform_transform:\n",
    "      # cannot use both uniform and denorm transform together\n",
    "      assert denorm_transform == None\n",
    "      image_tensor = (image_tensor + 1) / 2 # scale from [-1, 1] to [0, 1] space\n",
    "    image_unflat = image_tensor.detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()\n",
    "\n",
    "def save_model(model, output_filename):\n",
    "  torch.save(model.state_dict(), output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "139bf81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using class adapative layer!!!\n",
      "Output shape of unet is: torch.Size([7, 3, 64, 64])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 12, 64, 64]              36\n",
      "   FeatureMapBlock-2           [-1, 12, 64, 64]               0\n",
      "            Conv2d-3           [-1, 24, 64, 64]           2,616\n",
      "       BatchNorm2d-4           [-1, 24, 64, 64]              48\n",
      "           Dropout-5           [-1, 24, 64, 64]               0\n",
      "         LeakyReLU-6           [-1, 24, 64, 64]               0\n",
      "            Conv2d-7           [-1, 24, 64, 64]           5,208\n",
      "       BatchNorm2d-8           [-1, 24, 64, 64]              48\n",
      "           Dropout-9           [-1, 24, 64, 64]               0\n",
      "        LeakyReLU-10           [-1, 24, 64, 64]               0\n",
      "        MaxPool2d-11           [-1, 24, 32, 32]               0\n",
      " ContractingBlock-12           [-1, 24, 32, 32]               0\n",
      "        Embedding-13             [-1, 1, 1, 32]             576\n",
      "           Linear-14                   [-1, 24]             792\n",
      "           Linear-15                   [-1, 24]             792\n",
      "AdaINClassAdapativeLayer-16           [-1, 24, 32, 32]               0\n",
      "           Conv2d-17           [-1, 48, 32, 32]          10,416\n",
      "      BatchNorm2d-18           [-1, 48, 32, 32]              96\n",
      "          Dropout-19           [-1, 48, 32, 32]               0\n",
      "        LeakyReLU-20           [-1, 48, 32, 32]               0\n",
      "           Conv2d-21           [-1, 48, 32, 32]          20,784\n",
      "      BatchNorm2d-22           [-1, 48, 32, 32]              96\n",
      "          Dropout-23           [-1, 48, 32, 32]               0\n",
      "        LeakyReLU-24           [-1, 48, 32, 32]               0\n",
      "        MaxPool2d-25           [-1, 48, 16, 16]               0\n",
      " ContractingBlock-26           [-1, 48, 16, 16]               0\n",
      "           Conv2d-27           [-1, 96, 16, 16]          41,568\n",
      "      BatchNorm2d-28           [-1, 96, 16, 16]             192\n",
      "          Dropout-29           [-1, 96, 16, 16]               0\n",
      "        LeakyReLU-30           [-1, 96, 16, 16]               0\n",
      "           Conv2d-31           [-1, 96, 16, 16]          83,040\n",
      "      BatchNorm2d-32           [-1, 96, 16, 16]             192\n",
      "          Dropout-33           [-1, 96, 16, 16]               0\n",
      "        LeakyReLU-34           [-1, 96, 16, 16]               0\n",
      "        MaxPool2d-35             [-1, 96, 8, 8]               0\n",
      " ContractingBlock-36             [-1, 96, 8, 8]               0\n",
      "        Embedding-37             [-1, 1, 1, 32]             576\n",
      "           Linear-38                   [-1, 96]           3,168\n",
      "           Linear-39                   [-1, 96]           3,168\n",
      "AdaINClassAdapativeLayer-40             [-1, 96, 8, 8]               0\n",
      "           Conv2d-41            [-1, 192, 8, 8]         166,080\n",
      "      BatchNorm2d-42            [-1, 192, 8, 8]             384\n",
      "        LeakyReLU-43            [-1, 192, 8, 8]               0\n",
      "           Conv2d-44            [-1, 192, 8, 8]         331,968\n",
      "      BatchNorm2d-45            [-1, 192, 8, 8]             384\n",
      "        LeakyReLU-46            [-1, 192, 8, 8]               0\n",
      "        MaxPool2d-47            [-1, 192, 4, 4]               0\n",
      " ContractingBlock-48            [-1, 192, 4, 4]               0\n",
      "           Conv2d-49            [-1, 384, 4, 4]         663,936\n",
      "      BatchNorm2d-50            [-1, 384, 4, 4]             768\n",
      "        LeakyReLU-51            [-1, 384, 4, 4]               0\n",
      "           Conv2d-52            [-1, 384, 4, 4]       1,327,488\n",
      "      BatchNorm2d-53            [-1, 384, 4, 4]             768\n",
      "        LeakyReLU-54            [-1, 384, 4, 4]               0\n",
      "        MaxPool2d-55            [-1, 384, 2, 2]               0\n",
      " ContractingBlock-56            [-1, 384, 2, 2]               0\n",
      "           Conv2d-57            [-1, 768, 2, 2]       2,654,976\n",
      "      BatchNorm2d-58            [-1, 768, 2, 2]           1,536\n",
      "        LeakyReLU-59            [-1, 768, 2, 2]               0\n",
      "           Conv2d-60            [-1, 768, 2, 2]       5,309,184\n",
      "      BatchNorm2d-61            [-1, 768, 2, 2]           1,536\n",
      "        LeakyReLU-62            [-1, 768, 2, 2]               0\n",
      "        MaxPool2d-63            [-1, 768, 1, 1]               0\n",
      " ContractingBlock-64            [-1, 768, 1, 1]               0\n",
      "        Embedding-65             [-1, 1, 1, 32]             576\n",
      "           Linear-66                  [-1, 768]          25,344\n",
      "           Linear-67                  [-1, 768]          25,344\n",
      "AdaINClassAdapativeLayer-68            [-1, 768, 1, 1]               0\n",
      "      InjectNoise-69            [-1, 768, 1, 1]             768\n",
      "         Upsample-70            [-1, 768, 2, 2]               0\n",
      "           Conv2d-71            [-1, 384, 1, 1]       1,180,032\n",
      "           Conv2d-72            [-1, 384, 1, 1]       2,654,592\n",
      "      BatchNorm2d-73            [-1, 384, 1, 1]             768\n",
      "             ReLU-74            [-1, 384, 1, 1]               0\n",
      "           Conv2d-75            [-1, 384, 2, 2]         590,208\n",
      "      BatchNorm2d-76            [-1, 384, 2, 2]             768\n",
      "             ReLU-77            [-1, 384, 2, 2]               0\n",
      "   ExpandingBlock-78            [-1, 384, 2, 2]               0\n",
      "        Embedding-79             [-1, 1, 1, 32]             576\n",
      "           Linear-80                  [-1, 384]          12,672\n",
      "           Linear-81                  [-1, 384]          12,672\n",
      "AdaINClassAdapativeLayer-82            [-1, 384, 2, 2]               0\n",
      "      InjectNoise-83            [-1, 384, 2, 2]             384\n",
      "         Upsample-84            [-1, 384, 4, 4]               0\n",
      "           Conv2d-85            [-1, 192, 3, 3]         295,104\n",
      "           Conv2d-86            [-1, 192, 3, 3]         663,744\n",
      "      BatchNorm2d-87            [-1, 192, 3, 3]             384\n",
      "             ReLU-88            [-1, 192, 3, 3]               0\n",
      "           Conv2d-89            [-1, 192, 4, 4]         147,648\n",
      "      BatchNorm2d-90            [-1, 192, 4, 4]             384\n",
      "             ReLU-91            [-1, 192, 4, 4]               0\n",
      "   ExpandingBlock-92            [-1, 192, 4, 4]               0\n",
      "        Embedding-93             [-1, 1, 1, 32]             576\n",
      "           Linear-94                  [-1, 192]           6,336\n",
      "           Linear-95                  [-1, 192]           6,336\n",
      "AdaINClassAdapativeLayer-96            [-1, 192, 4, 4]               0\n",
      "      InjectNoise-97            [-1, 192, 4, 4]             192\n",
      "         Upsample-98            [-1, 192, 8, 8]               0\n",
      "           Conv2d-99             [-1, 96, 7, 7]          73,824\n",
      "          Conv2d-100             [-1, 96, 7, 7]         165,984\n",
      "     BatchNorm2d-101             [-1, 96, 7, 7]             192\n",
      "            ReLU-102             [-1, 96, 7, 7]               0\n",
      "          Conv2d-103             [-1, 96, 8, 8]          36,960\n",
      "     BatchNorm2d-104             [-1, 96, 8, 8]             192\n",
      "            ReLU-105             [-1, 96, 8, 8]               0\n",
      "  ExpandingBlock-106             [-1, 96, 8, 8]               0\n",
      "     InjectNoise-107             [-1, 96, 8, 8]              96\n",
      "        Upsample-108           [-1, 96, 16, 16]               0\n",
      "          Conv2d-109           [-1, 48, 15, 15]          18,480\n",
      "          Conv2d-110           [-1, 48, 15, 15]          41,520\n",
      "     BatchNorm2d-111           [-1, 48, 15, 15]              96\n",
      "            ReLU-112           [-1, 48, 15, 15]               0\n",
      "          Conv2d-113           [-1, 48, 16, 16]           9,264\n",
      "     BatchNorm2d-114           [-1, 48, 16, 16]              96\n",
      "            ReLU-115           [-1, 48, 16, 16]               0\n",
      "  ExpandingBlock-116           [-1, 48, 16, 16]               0\n",
      "       Embedding-117             [-1, 1, 1, 32]             576\n",
      "          Linear-118                   [-1, 48]           1,584\n",
      "          Linear-119                   [-1, 48]           1,584\n",
      "AdaINClassAdapativeLayer-120           [-1, 48, 16, 16]               0\n",
      "     InjectNoise-121           [-1, 48, 16, 16]              48\n",
      "        Upsample-122           [-1, 48, 32, 32]               0\n",
      "          Conv2d-123           [-1, 24, 31, 31]           4,632\n",
      "          Conv2d-124           [-1, 24, 31, 31]          10,392\n",
      "     BatchNorm2d-125           [-1, 24, 31, 31]              48\n",
      "            ReLU-126           [-1, 24, 31, 31]               0\n",
      "          Conv2d-127           [-1, 24, 32, 32]           2,328\n",
      "     BatchNorm2d-128           [-1, 24, 32, 32]              48\n",
      "            ReLU-129           [-1, 24, 32, 32]               0\n",
      "  ExpandingBlock-130           [-1, 24, 32, 32]               0\n",
      "     InjectNoise-131           [-1, 24, 32, 32]              24\n",
      "        Upsample-132           [-1, 24, 64, 64]               0\n",
      "          Conv2d-133           [-1, 12, 63, 63]           1,164\n",
      "          Conv2d-134           [-1, 12, 63, 63]           2,604\n",
      "     BatchNorm2d-135           [-1, 12, 63, 63]              24\n",
      "            ReLU-136           [-1, 12, 63, 63]               0\n",
      "          Conv2d-137           [-1, 12, 64, 64]             588\n",
      "     BatchNorm2d-138           [-1, 12, 64, 64]              24\n",
      "            ReLU-139           [-1, 12, 64, 64]               0\n",
      "  ExpandingBlock-140           [-1, 12, 64, 64]               0\n",
      "          Conv2d-141            [-1, 3, 64, 64]              39\n",
      " FeatureMapBlock-142            [-1, 3, 64, 64]               0\n",
      "            Tanh-143            [-1, 3, 64, 64]               0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moose_abdool/miniconda3/envs/cs236g_py37/lib/python3.7/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ph/g131tglj70v_hdzxdjcz34p00000gn/T/ipykernel_84099/354311762.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output shape of unet is: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_unet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/cs236g_py37/lib/python3.7/site-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m# assume 4 bytes/number (float on cuda).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mtotal_input_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0mtotal_output_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtotal_output\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# x2 for gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mtotal_params_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cs236g_py37/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   3050\u001b[0m     \"\"\"\n\u001b[1;32m   3051\u001b[0m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n\u001b[0;32m-> 3052\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   3053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cs236g_py37/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'tuple'"
     ]
    }
   ],
   "source": [
    "# Test out the conditional Unet with image input (to get # of parameters)\n",
    "test_unet =UNetConditionalImage(input_channels = 2, output_channels = 3, \n",
    "                            hidden_channels = 12, input_dim=64, \n",
    "                            use_class_embed=False, \n",
    "                            class_embed_size=16, use_conditional_layer_arch=False, vocab_size=16,\n",
    "                            inject_noise = True, use_class_adapt_layer = True)\n",
    "\n",
    "out = test_unet(torch.ones(7, 1, 64, 64), torch.ones(7, 1))\n",
    "\n",
    "print(\"Output shape of unet is: {}\".format(out.shape))\n",
    "\n",
    "summary(test_unet, [(1, 64, 64), (1, 1)], device = 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e28197ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape of unet is: torch.Size([7, 3, 64, 64])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         Embedding-1             [-1, 1, 1, 16]             256\n",
      "            Linear-2                 [-1, 1024]          33,792\n",
      "              ReLU-3                 [-1, 1024]               0\n",
      "            Linear-4                 [-1, 1024]       1,049,600\n",
      "              ReLU-5                 [-1, 1024]               0\n",
      "            Linear-6                   [-1, 32]          32,800\n",
      "    MappingNetwork-7                   [-1, 32]               0\n",
      "            Conv2d-8            [-1, 8, 64, 64]              16\n",
      "   FeatureMapBlock-9            [-1, 8, 64, 64]               0\n",
      "           Conv2d-10           [-1, 16, 64, 64]           1,168\n",
      "      BatchNorm2d-11           [-1, 16, 64, 64]              32\n",
      "          Dropout-12           [-1, 16, 64, 64]               0\n",
      "        LeakyReLU-13           [-1, 16, 64, 64]               0\n",
      "           Conv2d-14           [-1, 16, 64, 64]           2,320\n",
      "      BatchNorm2d-15           [-1, 16, 64, 64]              32\n",
      "          Dropout-16           [-1, 16, 64, 64]               0\n",
      "        LeakyReLU-17           [-1, 16, 64, 64]               0\n",
      "        MaxPool2d-18           [-1, 16, 32, 32]               0\n",
      " ContractingBlock-19           [-1, 16, 32, 32]               0\n",
      "           Conv2d-20           [-1, 32, 32, 32]           4,640\n",
      "      BatchNorm2d-21           [-1, 32, 32, 32]              64\n",
      "          Dropout-22           [-1, 32, 32, 32]               0\n",
      "        LeakyReLU-23           [-1, 32, 32, 32]               0\n",
      "           Conv2d-24           [-1, 32, 32, 32]           9,248\n",
      "      BatchNorm2d-25           [-1, 32, 32, 32]              64\n",
      "          Dropout-26           [-1, 32, 32, 32]               0\n",
      "        LeakyReLU-27           [-1, 32, 32, 32]               0\n",
      "        MaxPool2d-28           [-1, 32, 16, 16]               0\n",
      " ContractingBlock-29           [-1, 32, 16, 16]               0\n",
      "           Conv2d-30           [-1, 64, 16, 16]          18,496\n",
      "      BatchNorm2d-31           [-1, 64, 16, 16]             128\n",
      "          Dropout-32           [-1, 64, 16, 16]               0\n",
      "        LeakyReLU-33           [-1, 64, 16, 16]               0\n",
      "           Conv2d-34           [-1, 64, 16, 16]          36,928\n",
      "      BatchNorm2d-35           [-1, 64, 16, 16]             128\n",
      "          Dropout-36           [-1, 64, 16, 16]               0\n",
      "        LeakyReLU-37           [-1, 64, 16, 16]               0\n",
      "        MaxPool2d-38             [-1, 64, 8, 8]               0\n",
      " ContractingBlock-39             [-1, 64, 8, 8]               0\n",
      "           Conv2d-40            [-1, 128, 8, 8]          73,856\n",
      "      BatchNorm2d-41            [-1, 128, 8, 8]             256\n",
      "        LeakyReLU-42            [-1, 128, 8, 8]               0\n",
      "           Conv2d-43            [-1, 128, 8, 8]         147,584\n",
      "      BatchNorm2d-44            [-1, 128, 8, 8]             256\n",
      "        LeakyReLU-45            [-1, 128, 8, 8]               0\n",
      "        MaxPool2d-46            [-1, 128, 4, 4]               0\n",
      " ContractingBlock-47            [-1, 128, 4, 4]               0\n",
      "           Conv2d-48            [-1, 256, 4, 4]         295,168\n",
      "      BatchNorm2d-49            [-1, 256, 4, 4]             512\n",
      "        LeakyReLU-50            [-1, 256, 4, 4]               0\n",
      "           Conv2d-51            [-1, 256, 4, 4]         590,080\n",
      "      BatchNorm2d-52            [-1, 256, 4, 4]             512\n",
      "        LeakyReLU-53            [-1, 256, 4, 4]               0\n",
      "        MaxPool2d-54            [-1, 256, 2, 2]               0\n",
      " ContractingBlock-55            [-1, 256, 2, 2]               0\n",
      "           Conv2d-56            [-1, 512, 2, 2]       1,180,160\n",
      "      BatchNorm2d-57            [-1, 512, 2, 2]           1,024\n",
      "        LeakyReLU-58            [-1, 512, 2, 2]               0\n",
      "           Conv2d-59            [-1, 512, 2, 2]       2,359,808\n",
      "      BatchNorm2d-60            [-1, 512, 2, 2]           1,024\n",
      "        LeakyReLU-61            [-1, 512, 2, 2]               0\n",
      "        MaxPool2d-62            [-1, 512, 1, 1]               0\n",
      " ContractingBlock-63            [-1, 512, 1, 1]               0\n",
      "         Upsample-64            [-1, 512, 2, 2]               0\n",
      "           Conv2d-65            [-1, 256, 1, 1]         524,544\n",
      "           Conv2d-66            [-1, 256, 1, 1]       1,179,904\n",
      "      BatchNorm2d-67            [-1, 256, 1, 1]             512\n",
      "             ReLU-68            [-1, 256, 1, 1]               0\n",
      "           Conv2d-69            [-1, 256, 2, 2]         262,400\n",
      "      BatchNorm2d-70            [-1, 256, 2, 2]             512\n",
      "             ReLU-71            [-1, 256, 2, 2]               0\n",
      "   ExpandingBlock-72            [-1, 256, 2, 2]               0\n",
      "         Upsample-73            [-1, 256, 4, 4]               0\n",
      "           Conv2d-74            [-1, 128, 3, 3]         131,200\n",
      "           Conv2d-75            [-1, 128, 3, 3]         295,040\n",
      "      BatchNorm2d-76            [-1, 128, 3, 3]             256\n",
      "             ReLU-77            [-1, 128, 3, 3]               0\n",
      "           Conv2d-78            [-1, 128, 4, 4]          65,664\n",
      "      BatchNorm2d-79            [-1, 128, 4, 4]             256\n",
      "             ReLU-80            [-1, 128, 4, 4]               0\n",
      "   ExpandingBlock-81            [-1, 128, 4, 4]               0\n",
      "         Upsample-82            [-1, 128, 8, 8]               0\n",
      "           Conv2d-83             [-1, 64, 7, 7]          32,832\n",
      "           Conv2d-84             [-1, 64, 7, 7]          73,792\n",
      "      BatchNorm2d-85             [-1, 64, 7, 7]             128\n",
      "             ReLU-86             [-1, 64, 7, 7]               0\n",
      "           Conv2d-87             [-1, 64, 8, 8]          16,448\n",
      "      BatchNorm2d-88             [-1, 64, 8, 8]             128\n",
      "             ReLU-89             [-1, 64, 8, 8]               0\n",
      "   ExpandingBlock-90             [-1, 64, 8, 8]               0\n",
      "         Upsample-91           [-1, 64, 16, 16]               0\n",
      "           Conv2d-92           [-1, 32, 15, 15]           8,224\n",
      "           Conv2d-93           [-1, 32, 15, 15]          18,464\n",
      "      BatchNorm2d-94           [-1, 32, 15, 15]              64\n",
      "             ReLU-95           [-1, 32, 15, 15]               0\n",
      "           Conv2d-96           [-1, 32, 16, 16]           4,128\n",
      "      BatchNorm2d-97           [-1, 32, 16, 16]              64\n",
      "             ReLU-98           [-1, 32, 16, 16]               0\n",
      "   ExpandingBlock-99           [-1, 32, 16, 16]               0\n",
      "        Upsample-100           [-1, 32, 32, 32]               0\n",
      "          Conv2d-101           [-1, 16, 31, 31]           2,064\n",
      "          Conv2d-102           [-1, 16, 31, 31]           4,624\n",
      "     BatchNorm2d-103           [-1, 16, 31, 31]              32\n",
      "            ReLU-104           [-1, 16, 31, 31]               0\n",
      "          Conv2d-105           [-1, 16, 32, 32]           1,040\n",
      "     BatchNorm2d-106           [-1, 16, 32, 32]              32\n",
      "            ReLU-107           [-1, 16, 32, 32]               0\n",
      "  ExpandingBlock-108           [-1, 16, 32, 32]               0\n",
      "        Upsample-109           [-1, 16, 64, 64]               0\n",
      "          Conv2d-110            [-1, 8, 63, 63]             520\n",
      "          Conv2d-111            [-1, 8, 63, 63]           1,160\n",
      "     BatchNorm2d-112            [-1, 8, 63, 63]              16\n",
      "            ReLU-113            [-1, 8, 63, 63]               0\n",
      "          Conv2d-114            [-1, 8, 64, 64]             264\n",
      "     BatchNorm2d-115            [-1, 8, 64, 64]              16\n",
      "            ReLU-116            [-1, 8, 64, 64]               0\n",
      "  ExpandingBlock-117            [-1, 8, 64, 64]               0\n",
      "          Conv2d-118            [-1, 3, 64, 64]              27\n",
      " FeatureMapBlock-119            [-1, 3, 64, 64]               0\n",
      "            Tanh-120            [-1, 3, 64, 64]               0\n",
      "================================================================\n",
      "Total params: 8,464,307\n",
      "Trainable params: 8,464,307\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 13.71\n",
      "Params size (MB): 32.29\n",
      "Estimated Total Size (MB): 46.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test out the conditional Unet with vector + tiling input(to get # of parameters)\n",
    "test_unet = UNetConditional(input_channels = 1, output_channels = 3, \n",
    "                            hidden_channels = 8, input_dim=64, \n",
    "                            use_class_embed=True, z_dim = 16,\n",
    "                            class_embed_size=16, use_conditional_layer_arch=False, vocab_size=16,\n",
    "                            use_mapping_network = True, map_network_hidden_size = 1024\n",
    "                            )\n",
    "\n",
    "out = test_unet(torch.ones(7, 16), torch.ones(7, 1))\n",
    "\n",
    "print(\"Output shape of unet is: {}\".format(out.shape))\n",
    "\n",
    "summary(test_unet, [(1, 16), (1, 1)], device = 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d0a821f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of patchgan output is: torch.Size([7, 1, 4, 4])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         Embedding-1                   [-1, 16]             288\n",
      "            Conv2d-2            [-1, 2, 64, 64]              10\n",
      "   FeatureMapBlock-3            [-1, 2, 64, 64]               0\n",
      "            Conv2d-4            [-1, 4, 64, 64]              76\n",
      "         LeakyReLU-5            [-1, 4, 64, 64]               0\n",
      "            Conv2d-6            [-1, 4, 64, 64]             148\n",
      "         LeakyReLU-7            [-1, 4, 64, 64]               0\n",
      "         MaxPool2d-8            [-1, 4, 32, 32]               0\n",
      "  ContractingBlock-9            [-1, 4, 32, 32]               0\n",
      "           Conv2d-10            [-1, 8, 32, 32]             296\n",
      "      BatchNorm2d-11            [-1, 8, 32, 32]              16\n",
      "        LeakyReLU-12            [-1, 8, 32, 32]               0\n",
      "           Conv2d-13            [-1, 8, 32, 32]             584\n",
      "      BatchNorm2d-14            [-1, 8, 32, 32]              16\n",
      "        LeakyReLU-15            [-1, 8, 32, 32]               0\n",
      "        MaxPool2d-16            [-1, 8, 16, 16]               0\n",
      " ContractingBlock-17            [-1, 8, 16, 16]               0\n",
      "           Conv2d-18           [-1, 16, 16, 16]           1,168\n",
      "      BatchNorm2d-19           [-1, 16, 16, 16]              32\n",
      "        LeakyReLU-20           [-1, 16, 16, 16]               0\n",
      "           Conv2d-21           [-1, 16, 16, 16]           2,320\n",
      "      BatchNorm2d-22           [-1, 16, 16, 16]              32\n",
      "        LeakyReLU-23           [-1, 16, 16, 16]               0\n",
      "        MaxPool2d-24             [-1, 16, 8, 8]               0\n",
      " ContractingBlock-25             [-1, 16, 8, 8]               0\n",
      "           Conv2d-26             [-1, 32, 8, 8]           4,640\n",
      "      BatchNorm2d-27             [-1, 32, 8, 8]              64\n",
      "        LeakyReLU-28             [-1, 32, 8, 8]               0\n",
      "           Conv2d-29             [-1, 32, 8, 8]           9,248\n",
      "      BatchNorm2d-30             [-1, 32, 8, 8]              64\n",
      "        LeakyReLU-31             [-1, 32, 8, 8]               0\n",
      "        MaxPool2d-32             [-1, 32, 4, 4]               0\n",
      " ContractingBlock-33             [-1, 32, 4, 4]               0\n",
      "           Conv2d-34              [-1, 1, 4, 4]              33\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ph/g131tglj70v_hdzxdjcz34p00000gn/T/ipykernel_84099/959670785.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shape of patchgan output is: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatchgan_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_patchgan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/cs236g_py37/lib/python3.7/site-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m# assume 4 bytes/number (float on cuda).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mtotal_input_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0mtotal_output_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtotal_output\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# x2 for gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mtotal_params_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cs236g_py37/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   3050\u001b[0m     \"\"\"\n\u001b[1;32m   3051\u001b[0m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n\u001b[0;32m-> 3052\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   3053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cs236g_py37/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'tuple'"
     ]
    }
   ],
   "source": [
    "# What are the differences here?\n",
    "# PatchGan input is (3x96x96)\n",
    "# output is 6x6 patches if input dim is 96\n",
    "# output is 8x8 patches if input dim is 128\n",
    "# Basically, it's easy to change the shape of the input dimension image, we just create more patches\n",
    "\n",
    "test_patchgan = DiscriminatorPatchGANConditional(input_channels = 3, hidden_channels = 2, input_image_dim=64,\n",
    "                                                use_class_proj = False)\n",
    "\n",
    "patchgan_out = test_patchgan(torch.ones(7, 3, 64, 64), torch.ones(7, 1))\n",
    "\n",
    "print(\"Shape of patchgan output is: {}\".format(patchgan_out.shape))\n",
    "\n",
    "summary(test_patchgan, [(3, 64, 64), (1,1)], device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e784feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= Define the basic hyper-parameters =====\n",
    "\n",
    "\n",
    "# training epochs\n",
    "n_epochs = 1\n",
    "\n",
    "# Generator parameters\n",
    "use_unet_image = False\n",
    "use_unet_conditional = True\n",
    "\n",
    "assert use_unet_image != use_unet_conditional\n",
    "\n",
    "\n",
    "hidden_dim_gen = 8\n",
    "z_dim = 16 # dimension of noise vector (if using UNetConditional)\n",
    "gen_input_image_size = 64 # dimension of input image size (if using UNetConditionalImage)\n",
    "use_noise_upsampling = False\n",
    "original_noise_dim = 32\n",
    "use_gen_class_embed = True\n",
    "gen_class_embed_size = 16\n",
    "use_mapping_network = True\n",
    "map_network_hidden_size = 1024 # only used in UnetConditional\n",
    "use_conditional_layer_arch = False\n",
    "use_gen_dropout = False\n",
    "dropout_gen_prob = 0.1\n",
    "vocab_size = 13\n",
    "\n",
    "# noise and adapative class layer\n",
    "use_gen_noise = True # whether or not to inject noise to gen layers using the class\n",
    "use_class_ada_layer = False\n",
    "class_adapt_layer_embed_size = 32\n",
    "\n",
    "\n",
    "# Discriminator Parameters\n",
    "use_patchgan_disc=True\n",
    "use_dropout_disc = True\n",
    "patchgan_dropout = 0.1\n",
    "hidden_dim_disc = 32 # was 64\n",
    "disc_class_embed_size = 2\n",
    "use_class_embed_disc = True\n",
    "early_dropout = 0.4\n",
    "mid_dropout = 0.2\n",
    "late_dropout = 0.1\n",
    "use_gaussian_noise = True\n",
    "gaussian_noise_std = 0.02\n",
    "\n",
    "\n",
    "# General Parameters - batch size and dataset\n",
    "batch_size = 50 # 64 works\n",
    "#\n",
    "dataloader_name = \"conditional_64_no_shiny_mainclass_flip_rotate_standard_norm\"\n",
    "#\"conditional_64_dim_no_shiny_with_flip_and_rotate_and_standard_norm\"\n",
    "#\"conditional_64_dim_mainclass_with_shiny_flip_rotate_custom_norm\"\n",
    "\n",
    "# how often to display images and debug info. Basically, the numerator is how many images you want to\n",
    "# process before showing some debug info\n",
    "display_step = int((4000 / batch_size))\n",
    "periodic_saving = True\n",
    "# after how many epochs do you save the model?\n",
    "epoch_save_step = 20\n",
    "save_prefix = \"experiment_13/test_unet_and_dcdiscriminator_standard_noise_vec\"\n",
    "imgs_to_display = 10\n",
    "\n",
    "print(\"Planning to display images every {} steps\".format(display_step))\n",
    "\n",
    "# other sources say 0.00275 works better...but the DCGAn paper used 0.0002 (ie. about 10-4 instead of 10-3)\n",
    "gen_lr = 0.0002 # 0.0002 works for both, but takes at least 10-15 epochs before anything interesting happens?\n",
    "disc_lr = 0.0002\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "disc_repeats = 1\n",
    "gen_repeats = 1\n",
    "\n",
    "# loss functions used\n",
    "use_wgan_loss = False\n",
    "if use_wgan_loss:\n",
    "    # not performannt enough\n",
    "  gen_loss_func = get_generator_loss_func(\"wgan_gen_loss\")\n",
    "  disc_loss_func = get_disc_loss_func(\"wgan_disc_loss\")\n",
    "  c_lambda = 10\n",
    "else:\n",
    "  gen_loss_func = get_generator_loss_func(\"basic_gen_loss\") #get_generator_loss_func(\"basic_gen_loss_with_logits\")\n",
    "  disc_loss_func = get_disc_loss_func(\"noisy_disc_loss\") #get_disc_loss_func(\"noisy_patchgan_disc_loss\") #can also do noisy here\n",
    "\n",
    "assert imgs_to_display <= batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d8e9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataloader, based on the appropriate batch size. \n",
    "\n",
    "use_reduced_types = True\n",
    "show_preview = True\n",
    "\n",
    "pkmn_dataloader, denorm_transform = get_pkmn_dataloader(dataloader_name, batch_size,num_workers=0)\n",
    "test_size = 10\n",
    "\n",
    "# show a batch before and after denorm\n",
    "test_data_iter = iter(pkmn_dataloader)\n",
    "test_images, test_labels = next(test_data_iter)\n",
    "\n",
    "print(\"length of dataset (number of steps) is: {}, total size is: {}\".format(len(pkmn_dataloader), len(pkmn_dataloader)*batch_size))\n",
    "\n",
    "if show_preview:\n",
    "  show_tensor_images(test_images[0:test_size], num_images = test_size, size = (3,64,64), denorm_transform = None)\n",
    "  show_tensor_images(test_images[0:test_size], num_images = test_size, size = (3,64,64), denorm_transform = denorm_transform)\n",
    "\n",
    "if use_reduced_types:\n",
    "  valid_types = REDUCED_PKMN_TYPES\n",
    "  class_idx_to_type = CLASS_IDX_2_PKMN_TYPE_REDUCED\n",
    "else:\n",
    "  valid_types = PKMN_TYPES\n",
    "  class_idx_to_type = CLASS_IDX_2_PKMN_TYPE\n",
    "  \n",
    "num_pkmn_types = len(valid_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a1243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= Define the basic hyper-parameters =====\n",
    "\n",
    "\n",
    "# training epochs\n",
    "n_epochs = 200\n",
    "\n",
    "# Generator parameters\n",
    "use_unet_image = False\n",
    "use_unet_conditional = True\n",
    "\n",
    "assert use_unet_image != use_unet_conditional\n",
    "\n",
    "hidden_dim_gen = 12\n",
    "z_dim = 16 # dimension of noise vector (if using UNetConditional)\n",
    "gen_input_image_size = 64 # dimension of input image size (if using UNetConditionalImage)\n",
    "use_noise_upsampling = False\n",
    "original_noise_dim = 32\n",
    "use_gen_class_embed = True\n",
    "gen_class_embed_size = 16\n",
    "use_mapping_network = False\n",
    "map_network_hidden_size = 512 # only used in UnetConditional\n",
    "use_conditional_layer_arch = False\n",
    "use_gen_dropout = False\n",
    "dropout_gen_prob = 0.1\n",
    "vocab_size = 13\n",
    "\n",
    "# noise and adapative class layer\n",
    "use_gen_noise = False\n",
    "use_class_ada_layer = True\n",
    "class_adapt_layer_embed_size = 32\n",
    "\n",
    "\n",
    "# Discriminator Parameters\n",
    "use_patchgan_disc=True\n",
    "use_dropout_disc = True\n",
    "patchgan_dropout = 0.1\n",
    "hidden_dim_disc = 32 # was 64\n",
    "disc_class_embed_size = 4\n",
    "use_class_embed_disc = True\n",
    "early_dropout = 0.4\n",
    "mid_dropout = 0.2\n",
    "late_dropout = 0.1\n",
    "use_gaussian_noise = True\n",
    "gaussian_noise_std = 0.02\n",
    "\n",
    "\n",
    "# General Parameters - batch size and dataset\n",
    "batch_size = 50 # 64 works\n",
    "#\n",
    "dataloader_name = \"conditional_64_no_shiny_mainclass_flip_rotate_standard_norm\"\n",
    "#\"conditional_64_dim_no_shiny_with_flip_and_rotate_and_standard_norm\"\n",
    "#\"conditional_64_dim_mainclass_with_shiny_flip_rotate_custom_norm\"\n",
    "\n",
    "# how often to display images and debug info. Basically, the numerator is how many images you want to\n",
    "# process before showing some debug info\n",
    "display_step = int((4000 / batch_size))\n",
    "periodic_saving = True\n",
    "# after how many epochs do you save the model?\n",
    "epoch_save_step = 20\n",
    "save_prefix = \"experiment_13/test_unet_and_dcdiscriminator_standard_noise_vec\"\n",
    "imgs_to_display = 10\n",
    "\n",
    "print(\"Planning to display images every {} steps\".format(display_step))\n",
    "\n",
    "# other sources say 0.00275 works better...but the DCGAn paper used 0.0002 (ie. about 10-4 instead of 10-3)\n",
    "gen_lr = 0.0002 # 0.0002 works for both, but takes at least 10-15 epochs before anything interesting happens?\n",
    "disc_lr = 0.0002\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "disc_repeats = 1\n",
    "gen_repeats = 1\n",
    "\n",
    "# loss functions used\n",
    "use_wgan_loss = False\n",
    "if use_wgan_loss:\n",
    "    # not performannt enough\n",
    "  gen_loss_func = get_generator_loss_func(\"wgan_gen_loss\")\n",
    "  disc_loss_func = get_disc_loss_func(\"wgan_disc_loss\")\n",
    "  c_lambda = 10\n",
    "else:\n",
    "    if use_patchgan_disc:\n",
    "        gen_loss_func = get_generator_loss_func(\"basic_gen_loss\") #get_generator_loss_func(\"basic_gen_loss_with_logits\")\n",
    "        disc_loss_func = get_disc_loss_func(\"noisy_disc_loss\") #get_disc_loss_func(\"noisy_patchgan_disc_loss\") #can also do noisy here\n",
    "    else:\n",
    "        gen_loss_func = get_generator_loss_func(\"basic_gen_loss\") #get_generator_loss_func(\"basic_gen_loss_with_logits\")\n",
    "        disc_loss_func = get_disc_loss_func(\"noisy_disc_loss\") #get_disc_loss_func(\"noisy_patchgan_disc_loss\") #can also do noisy here\n",
    "\n",
    "assert imgs_to_display <= batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59280606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "cur_step = 0\n",
    "generator_losses = []\n",
    "discriminator_losses = []\n",
    "discriminator_fake_preds = [] # median value of P(real) the discriminator predicts on the fake images (per batch)\n",
    "discriminator_real_preds = [] # median value of P(real) the discriminator predicts on the real images (per batch)\n",
    "if use_patchgan_disc:\n",
    "    agg_func = nn.Sigmoid() # use this if you have logit outputs\n",
    "else:\n",
    "    agg_func = nn.Identity()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Dataloader returns the (real_images, labels)\n",
    "    for real, true_labels in tqdm(pkmn_dataloader):\n",
    "        cur_batch_size = len(real)\n",
    "        real = real.to(device)\n",
    "        true_labels = true_labels.to(device)\n",
    "        \n",
    "        mean_iteration_discriminator_loss = 0\n",
    "        for _ in range(disc_repeats):\n",
    "            ### Update discriminator ###\n",
    "            disc_opt.zero_grad()\n",
    "            if use_unet_image:\n",
    "              fake_noise = get_image_noise(cur_batch_size, gen_input_image_size, device, upsampling = use_noise_upsampling,noise_dim = original_noise_dim) #get_noise(cur_batch_size, z_dim, device=device)\n",
    "            else:\n",
    "              fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
    "\n",
    "            fake = gen(fake_noise, true_labels)\n",
    "            \n",
    "            disc_fake_pred = disc(fake.detach(), true_labels)\n",
    "            disc_real_pred = disc(real, true_labels)\n",
    "\n",
    "            \n",
    "            if use_wgan_loss:\n",
    "              epsilon = torch.rand(len(real), 1, 1, 1, device=device, requires_grad=True)\n",
    "              gradient = get_gradient(disc, real, true_labels, fake.detach(), epsilon)\n",
    "              gp = gradient_penalty(gradient)\n",
    "              # how should we track these two relative losses ?\n",
    "              disc_loss = disc_loss_func(disc_fake_pred, disc_real_pred, gp, c_lambda)              \n",
    "\n",
    "            else:\n",
    "              # compute discriminator loss normally\n",
    "              disc_loss = disc_loss_func(disc_fake_pred, disc_real_pred, device)\n",
    "            \n",
    "            # Keep track of the average discriminator loss in this batch\n",
    "            mean_iteration_discriminator_loss += disc_loss.item() / disc_repeats\n",
    "            \n",
    "            # Update gradients\n",
    "            # when using WGAN, we have retain_graph = True, but it probably takes longer\n",
    "            disc_loss.backward(retain_graph=use_wgan_loss)\n",
    "            \n",
    "            # Update optimizer\n",
    "            disc_opt.step()\n",
    "            \n",
    "        discriminator_losses += [mean_iteration_discriminator_loss]\n",
    "        # notice this only takes the last one from the iteration (if you run the discriminator multiple times)\n",
    "        # use a Sigmoid here to go from logits back into the P(real) space\n",
    "        discriminator_fake_preds += [agg_func(torch.mean(disc_fake_pred).detach())]\n",
    "        discriminator_real_preds += [agg_func(torch.mean(disc_real_pred).detach())]\n",
    "\n",
    "        ### Update generator ###\n",
    "        mean_iteration_gen_loss = 0\n",
    "        for _ in range(gen_repeats):\n",
    "          gen_opt.zero_grad()\n",
    "          if use_unet_image:\n",
    "            fake_noise_2 = get_image_noise(cur_batch_size, gen_input_image_size, device, upsampling = use_noise_upsampling,noise_dim = original_noise_dim) #get_noise(cur_batch_size, z_dim, device=device)\n",
    "          else:\n",
    "            fake_noise_2 = get_noise(cur_batch_size, z_dim, device=device)          \n",
    "          fake_2 = gen(fake_noise_2, true_labels)\n",
    "          disc_fake_pred = disc(fake_2, true_labels)\n",
    "\n",
    "          # compute gen loss\n",
    "          gen_loss = gen_loss_func(disc_fake_pred, device)\n",
    "          \n",
    "          mean_iteration_gen_loss += gen_loss.item() / gen_repeats\n",
    "          \n",
    "          gen_loss.backward()\n",
    "\n",
    "          # Update the weights\n",
    "          gen_opt.step()\n",
    "\n",
    "        # Keep track of the average generator loss\n",
    "        generator_losses += [mean_iteration_gen_loss]\n",
    "        \n",
    "        ### Visualization code ###\n",
    "        if cur_step % display_step == 0 and cur_step > 0:\n",
    "            gen_mean = sum(generator_losses[-display_step:]) / display_step\n",
    "            disc_mean = sum(discriminator_losses[-display_step:]) / display_step\n",
    "            # maybe print out the last values here ? To see how stable it is overtime ? These all seem to be very close to 0.5 / 1\n",
    "            disc_prediction_real = sum(discriminator_real_preds[-display_step:]) / display_step\n",
    "            disc_prediction_fake = sum(discriminator_fake_preds[-display_step:]) / display_step\n",
    "            print(f\"Step {cur_step}: Epoch: {epoch}: Generator loss: {gen_mean}, discriminator loss: {disc_mean} mean disc pred on real images: {disc_prediction_real}, fake images: {disc_prediction_fake}\")\n",
    "            show_tensor_images(fake[0:imgs_to_display], imgs_to_display, size = (3,64,64), denorm_transform = denorm_transform)\n",
    "            show_tensor_images(real[0:imgs_to_display], imgs_to_display, size = (3,64,64), denorm_transform = denorm_transform)\n",
    "            \n",
    "            ground_truth_types = [class_idx_to_type[class_idx] for class_idx in true_labels[0:imgs_to_display].cpu().numpy()]\n",
    "            print(\"Pokemon types we are trying to generate are: {} \\n    \\t \\t \\t \\t \\t {}\".format(ground_truth_types[0:5], ground_truth_types[5:]))\n",
    "            \n",
    "            step_bins = 20\n",
    "            \n",
    "            # todo: add proper labels to this plot\n",
    "            num_examples = (len(generator_losses) // step_bins) * step_bins\n",
    "            plt.plot(\n",
    "                range(num_examples // step_bins), \n",
    "                torch.Tensor(generator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                label=\"Generator Loss\"\n",
    "            )\n",
    "            plt.plot(\n",
    "                range(num_examples // step_bins), \n",
    "                torch.Tensor(discriminator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                label=\"discriminator Loss\"\n",
    "            )\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        \n",
    "        # increase the current step (ie. one batch)\n",
    "        cur_step += 1\n",
    "        \n",
    "    if periodic_saving and epoch % epoch_save_step == 0 and epoch_save_step > 0:\n",
    "      outfile_name = \"{}_{}.pt\".format(save_prefix, cur_step)\n",
    "      print(\"===== Saving intermediate model with name {} ! ====\".format(outfile_name))\n",
    "      save_model(gen, outfile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f627c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "\n",
    "out_file = \"experiment_11/unet_and_dcgan_exp_11_fulltrain.pt\"\n",
    "  \n",
    "save_model(gen, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da493fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model for inference and generate some random classes\n",
    "\n",
    "gen.load_state_dict(torch.load(\"{}\".format(out_file)))\n",
    "\n",
    "# Performing inference - actually, maybe I ran some other cell after this so it's not really well defined\n",
    "num_samples = 10\n",
    "\n",
    "if use_unet_image:\n",
    "    sample_vector = get_image_noise(num_samples, gen_input_image_size, device, upsampling = use_noise_upsampling,noise_dim = original_noise_dim) #get_noise(cur_batch_size, z_dim, device=device)\n",
    "else:\n",
    "    sample_vector = get_noise(num_samples, z_dim, device=device)    \n",
    "\n",
    "random_classes = torch.randint(low = 0, high = num_pkmn_types, size = (num_samples,)).to(device)\n",
    "\n",
    "fake_images = gen(sample_vector, random_classes)\n",
    "\n",
    "#output_size = gen.output_dim\n",
    "# + 0.9\n",
    "show_tensor_images(fake_images, num_images=num_samples, size=(1,256, 256), use_uniform_transform = True, denorm_transform = None)\n",
    "\n",
    "\n",
    "pkmn_classes = [class_idx_to_type[class_idx] for class_idx in random_classes.cpu().numpy()]\n",
    "print(\"Pokemon types we are trying to generate are: {} \\n    \\t \\t \\t \\t \\t {}\".format(pkmn_classes[0:5], pkmn_classes[5:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f9caf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples of a specific type from the model\n",
    "target_type = \"Fire\"\n",
    "class_idx = valid_types.index(target_type)\n",
    "\n",
    "class_tiled = torch.from_numpy(np.array([class_idx] * num_samples)).to(device)\n",
    "\n",
    "if use_unet_image:\n",
    "    sample_vector = get_image_noise(num_samples, gen_input_image_size, device, upsampling = use_noise_upsampling,noise_dim = original_noise_dim) #get_noise(cur_batch_size, z_dim, device=device)\n",
    "else:\n",
    "    sample_vector = get_noise(num_samples, z_dim, device=device)    \n",
    "\n",
    "\n",
    "fake_images = gen(sample_vector, class_tiled)\n",
    "\n",
    "# + 0.9\n",
    "show_tensor_images(fake_images, num_images=num_samples, size=(1,256, 256), use_uniform_transform = True, denorm_transform = None)\n",
    "\n",
    "\n",
    "pkmn_classes = [class_idx_to_type[class_idx] for class_idx in class_tiled.cpu().numpy()]\n",
    "print(\"Pokemon types we are trying to generate are: {} \\n    \\t \\t \\t \\t \\t {}\".format(pkmn_classes[0:5], pkmn_classes[5:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e476b84f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
