{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0a3be7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0) # Set for testing purposes, please do not change!\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# library to get dataloader\n",
    "from dataloaders import get_pkmn_dataloader\n",
    "\n",
    "# library to get loss functions\n",
    "from loss_functions import get_generator_loss_func,get_disc_loss_func,gradient_penalty,get_gradient\n",
    "\n",
    "# generators and discriminators\n",
    "from DCGeneratorCustom import DCGeneratorCustom\n",
    "from DCDiscriminatorCustom import DCDiscriminatorCustom\n",
    "from DCGeneratorStandard import DCGeneratorStandard\n",
    "from DCDiscriminatorStandard import DCDiscriminatorStandard\n",
    "from DCDiscriminatorStandardDropout import DCDiscriminatorStandardDropout\n",
    "from DiscriminatorPatchGAN import DiscriminatorPatchGAN,DiscriminatorPatchGANConditional\n",
    "from DCGeneratorConditionalLarge import DCGeneratorConditionalLarge\n",
    "\n",
    "from DCGeneratorConditional import DCGeneratorConditional\n",
    "from DCGeneratorConditionalLarge import DCGeneratorConditionalLarge\n",
    "from DCDiscriminatorConditional import DCDiscriminatorConditional\n",
    "from DCDiscriminatorConditionalLarge import DCDiscriminatorConditionalLarge\n",
    "from UNetArchitecture import UNet,UNetConditional\n",
    "\n",
    "# util methods\n",
    "from utils import get_noise\n",
    "\n",
    "# constants\n",
    "from pkmn_constants import PKMN_TYPES,CLASS_IDX_2_PKMN_TYPE,NUM_PKMN_TYPES,REDUCED_PKMN_TYPES,CLASS_IDX_2_PKMN_TYPE_REDUCED\n",
    "\n",
    "# whether to use CPU/GPU (pass this along everywhere)\n",
    "device_str = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device_str)\n",
    "\n",
    "print(\"Using device: {}\".format(device_str))\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a100e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.2\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "\n",
    "# if apply_denormalization is true, then we re-scale the images back \n",
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28), denorm_transform = None, use_uniform_transform = False):\n",
    "    '''\n",
    "    Function for visualizing images: Given a tensor of images, number of images, and\n",
    "    size per image, plots and prints the images in an uniform grid.\n",
    "    '''\n",
    "    \n",
    "    # We don't specifically need this since we are doing the denormalization ourself\n",
    "    \n",
    "    if denorm_transform is not None:\n",
    "      assert use_uniform_transform == False\n",
    "      image_tensor = denorm_transform(image_tensor)\n",
    "    if use_uniform_transform:\n",
    "      # cannot use both uniform and denorm transform together\n",
    "      assert denorm_transform == None\n",
    "      image_tensor = (image_tensor + 1) / 2 # scale from [-1, 1] to [0, 1] space\n",
    "    image_unflat = image_tensor.detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()\n",
    "\n",
    "def save_model(model, output_filename):\n",
    "  torch.save(model.state_dict(), output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "139bf81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape of unet is: torch.Size([7, 3, 64, 64])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 2, 96, 96]               4\n",
      "   FeatureMapBlock-2            [-1, 2, 96, 96]               0\n",
      "            Conv2d-3            [-1, 4, 96, 96]              76\n",
      "       BatchNorm2d-4            [-1, 4, 96, 96]               8\n",
      "           Dropout-5            [-1, 4, 96, 96]               0\n",
      "         LeakyReLU-6            [-1, 4, 96, 96]               0\n",
      "            Conv2d-7            [-1, 4, 96, 96]             148\n",
      "       BatchNorm2d-8            [-1, 4, 96, 96]               8\n",
      "           Dropout-9            [-1, 4, 96, 96]               0\n",
      "        LeakyReLU-10            [-1, 4, 96, 96]               0\n",
      "        MaxPool2d-11            [-1, 4, 48, 48]               0\n",
      " ContractingBlock-12            [-1, 4, 48, 48]               0\n",
      "           Conv2d-13            [-1, 8, 48, 48]             296\n",
      "      BatchNorm2d-14            [-1, 8, 48, 48]              16\n",
      "          Dropout-15            [-1, 8, 48, 48]               0\n",
      "        LeakyReLU-16            [-1, 8, 48, 48]               0\n",
      "           Conv2d-17            [-1, 8, 48, 48]             584\n",
      "      BatchNorm2d-18            [-1, 8, 48, 48]              16\n",
      "          Dropout-19            [-1, 8, 48, 48]               0\n",
      "        LeakyReLU-20            [-1, 8, 48, 48]               0\n",
      "        MaxPool2d-21            [-1, 8, 24, 24]               0\n",
      " ContractingBlock-22            [-1, 8, 24, 24]               0\n",
      "           Conv2d-23           [-1, 16, 24, 24]           1,168\n",
      "      BatchNorm2d-24           [-1, 16, 24, 24]              32\n",
      "          Dropout-25           [-1, 16, 24, 24]               0\n",
      "        LeakyReLU-26           [-1, 16, 24, 24]               0\n",
      "           Conv2d-27           [-1, 16, 24, 24]           2,320\n",
      "      BatchNorm2d-28           [-1, 16, 24, 24]              32\n",
      "          Dropout-29           [-1, 16, 24, 24]               0\n",
      "        LeakyReLU-30           [-1, 16, 24, 24]               0\n",
      "        MaxPool2d-31           [-1, 16, 12, 12]               0\n",
      " ContractingBlock-32           [-1, 16, 12, 12]               0\n",
      "           Conv2d-33           [-1, 32, 12, 12]           4,640\n",
      "      BatchNorm2d-34           [-1, 32, 12, 12]              64\n",
      "        LeakyReLU-35           [-1, 32, 12, 12]               0\n",
      "           Conv2d-36           [-1, 32, 12, 12]           9,248\n",
      "      BatchNorm2d-37           [-1, 32, 12, 12]              64\n",
      "        LeakyReLU-38           [-1, 32, 12, 12]               0\n",
      "        MaxPool2d-39             [-1, 32, 6, 6]               0\n",
      " ContractingBlock-40             [-1, 32, 6, 6]               0\n",
      "           Conv2d-41             [-1, 64, 6, 6]          18,496\n",
      "      BatchNorm2d-42             [-1, 64, 6, 6]             128\n",
      "        LeakyReLU-43             [-1, 64, 6, 6]               0\n",
      "           Conv2d-44             [-1, 64, 6, 6]          36,928\n",
      "      BatchNorm2d-45             [-1, 64, 6, 6]             128\n",
      "        LeakyReLU-46             [-1, 64, 6, 6]               0\n",
      "        MaxPool2d-47             [-1, 64, 3, 3]               0\n",
      " ContractingBlock-48             [-1, 64, 3, 3]               0\n",
      "           Conv2d-49            [-1, 128, 3, 3]          73,856\n",
      "      BatchNorm2d-50            [-1, 128, 3, 3]             256\n",
      "        LeakyReLU-51            [-1, 128, 3, 3]               0\n",
      "           Conv2d-52            [-1, 128, 3, 3]         147,584\n",
      "      BatchNorm2d-53            [-1, 128, 3, 3]             256\n",
      "        LeakyReLU-54            [-1, 128, 3, 3]               0\n",
      "        MaxPool2d-55            [-1, 128, 1, 1]               0\n",
      " ContractingBlock-56            [-1, 128, 1, 1]               0\n",
      "         Upsample-57            [-1, 128, 2, 2]               0\n",
      "           Conv2d-58             [-1, 64, 1, 1]          32,832\n",
      "           Conv2d-59             [-1, 64, 1, 1]          73,792\n",
      "      BatchNorm2d-60             [-1, 64, 1, 1]             128\n",
      "             ReLU-61             [-1, 64, 1, 1]               0\n",
      "           Conv2d-62             [-1, 64, 2, 2]          16,448\n",
      "      BatchNorm2d-63             [-1, 64, 2, 2]             128\n",
      "             ReLU-64             [-1, 64, 2, 2]               0\n",
      "   ExpandingBlock-65             [-1, 64, 2, 2]               0\n",
      "         Upsample-66             [-1, 64, 4, 4]               0\n",
      "           Conv2d-67             [-1, 32, 3, 3]           8,224\n",
      "           Conv2d-68             [-1, 32, 3, 3]          18,464\n",
      "      BatchNorm2d-69             [-1, 32, 3, 3]              64\n",
      "             ReLU-70             [-1, 32, 3, 3]               0\n",
      "           Conv2d-71             [-1, 32, 4, 4]           4,128\n",
      "      BatchNorm2d-72             [-1, 32, 4, 4]              64\n",
      "             ReLU-73             [-1, 32, 4, 4]               0\n",
      "   ExpandingBlock-74             [-1, 32, 4, 4]               0\n",
      "         Upsample-75             [-1, 32, 8, 8]               0\n",
      "           Conv2d-76             [-1, 16, 7, 7]           2,064\n",
      "           Conv2d-77             [-1, 16, 7, 7]           4,624\n",
      "      BatchNorm2d-78             [-1, 16, 7, 7]              32\n",
      "             ReLU-79             [-1, 16, 7, 7]               0\n",
      "           Conv2d-80             [-1, 16, 8, 8]           1,040\n",
      "      BatchNorm2d-81             [-1, 16, 8, 8]              32\n",
      "             ReLU-82             [-1, 16, 8, 8]               0\n",
      "   ExpandingBlock-83             [-1, 16, 8, 8]               0\n",
      "         Upsample-84           [-1, 16, 16, 16]               0\n",
      "           Conv2d-85            [-1, 8, 15, 15]             520\n",
      "           Conv2d-86            [-1, 8, 15, 15]           1,160\n",
      "      BatchNorm2d-87            [-1, 8, 15, 15]              16\n",
      "             ReLU-88            [-1, 8, 15, 15]               0\n",
      "           Conv2d-89            [-1, 8, 16, 16]             264\n",
      "      BatchNorm2d-90            [-1, 8, 16, 16]              16\n",
      "             ReLU-91            [-1, 8, 16, 16]               0\n",
      "   ExpandingBlock-92            [-1, 8, 16, 16]               0\n",
      "         Upsample-93            [-1, 8, 32, 32]               0\n",
      "           Conv2d-94            [-1, 4, 31, 31]             132\n",
      "           Conv2d-95            [-1, 4, 31, 31]             292\n",
      "      BatchNorm2d-96            [-1, 4, 31, 31]               8\n",
      "             ReLU-97            [-1, 4, 31, 31]               0\n",
      "           Conv2d-98            [-1, 4, 32, 32]              68\n",
      "      BatchNorm2d-99            [-1, 4, 32, 32]               8\n",
      "            ReLU-100            [-1, 4, 32, 32]               0\n",
      "  ExpandingBlock-101            [-1, 4, 32, 32]               0\n",
      "        Upsample-102            [-1, 4, 64, 64]               0\n",
      "          Conv2d-103            [-1, 2, 63, 63]              34\n",
      "          Conv2d-104            [-1, 2, 63, 63]              74\n",
      "     BatchNorm2d-105            [-1, 2, 63, 63]               4\n",
      "            ReLU-106            [-1, 2, 63, 63]               0\n",
      "          Conv2d-107            [-1, 2, 64, 64]              18\n",
      "     BatchNorm2d-108            [-1, 2, 64, 64]               4\n",
      "            ReLU-109            [-1, 2, 64, 64]               0\n",
      "  ExpandingBlock-110            [-1, 2, 64, 64]               0\n",
      "          Conv2d-111            [-1, 3, 64, 64]               9\n",
      " FeatureMapBlock-112            [-1, 3, 64, 64]               0\n",
      "            Tanh-113            [-1, 3, 64, 64]               0\n",
      "================================================================\n",
      "Total params: 461,047\n",
      "Trainable params: 461,047\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 6.33\n",
      "Params size (MB): 1.76\n",
      "Estimated Total Size (MB): 8.09\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# testing if we can create and summarize the Unet\n",
    "# Input is (bs, z_dim)\n",
    "# output is (3, 96, 96) image (difficult to change this!) --> Does this even depend on the input shape ?\n",
    "\n",
    "# what does the conditional case look like ?\n",
    "\n",
    "z_dim = 30\n",
    "\n",
    "test_unet = UNetConditional(input_channels = 1, output_channels = 3, \n",
    "                            hidden_channels = 2, input_dim=96, z_dim = z_dim, use_class_embed=False, \n",
    "                            class_embed_size=16, use_conditional_layer_arch=False)\n",
    "\n",
    "out = test_unet(torch.ones(7, z_dim), torch.ones(7, 1))\n",
    "\n",
    "print(\"Output shape of unet is: {}\".format(out.shape))\n",
    "\n",
    "summary(test_unet, [(1, z_dim), (1, 1)], device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0a821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the differences here?\n",
    "# PatchGan input is (3x96x96)\n",
    "# output is 6x6 patches if input dim is 96\n",
    "# output is 8x8 patches if input dim is 128\n",
    "# Basically, it's easy to change the shape of the input dimension image, we just create more patches\n",
    "\n",
    "test_patchgan = DiscriminatorPatchGANConditional(input_channels = 3, hidden_channels = 2)\n",
    "\n",
    "patchgan_out = test_patchgan(torch.ones(7, 3, 96, 96), torch.ones(7, 1))\n",
    "\n",
    "print(\"Shape of patchgan output is: {}\".format(patchgan_out.shape))\n",
    "\n",
    "summary(test_patchgan, [(3, 96, 96), (1,1)], device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e784feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= Define the basic hyper-parameters =====\n",
    "\n",
    "\n",
    "# training epochs\n",
    "n_epochs = 250\n",
    "\n",
    "# dimension of noise vector\n",
    "z_dim = 64 - 18\n",
    "# hidden dimensions\n",
    "hidden_dim_gen = 14 # was 10\n",
    "hidden_dim_disc = 32 # was 64\n",
    "disc_class_embed_size = 2\n",
    "batch_size = 96 # 64 works\n",
    "# how often to display images and debug info. Basically, the numerator is how many images you want to\n",
    "# process before showing some debug info\n",
    "display_step = int((4000 / batch_size))\n",
    "periodic_saving = True\n",
    "# after how many epochs do you save the model?\n",
    "epoch_save_step = 20\n",
    "save_prefix = \"experiment_10/test_unet_and_dcdiscriminator\"\n",
    "imgs_to_display = 10\n",
    "\n",
    "print(\"Planning to display images every {} steps\".format(display_step))\n",
    "\n",
    "# other sources say 0.00275 works better...but the DCGAn paper used 0.0002 (ie. about 10-4 instead of 10-3)\n",
    "gen_lr = 0.0002 # 0.0002 works for both, but takes at least 10-15 epochs before anything interesting happens?\n",
    "disc_lr = 0.0002\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "disc_repeats = 1\n",
    "gen_repeats = 1\n",
    "\n",
    "# loss functions\n",
    "use_wgan_loss = False\n",
    "if use_wgan_loss:\n",
    "    # not performannt enough\n",
    "  gen_loss_func = get_generator_loss_func(\"wgan_gen_loss\")\n",
    "  disc_loss_func = get_disc_loss_func(\"wgan_disc_loss\")\n",
    "  c_lambda = 10\n",
    "else:\n",
    "  gen_loss_func = get_generator_loss_func(\"basic_gen_loss\") #get_generator_loss_func(\"basic_gen_loss_with_logits\")\n",
    "  disc_loss_func = get_disc_loss_func(\"mse_disc_loss_noisy\") #get_disc_loss_func(\"noisy_patchgan_disc_loss\") #can also do noisy here\n",
    "\n",
    "assert imgs_to_display <= batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d8e9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataloader, based on the appropriate batch size. \n",
    "\n",
    "use_reduced_types = True\n",
    "show_preview = True\n",
    "dataloader_name = \"conditional_64_no_shiny_mainclass_flip_rotate_standard_norm\"\n",
    "\n",
    "pkmn_dataloader, denorm_transform = get_pkmn_dataloader(dataloader_name, batch_size,num_workers=0)\n",
    "test_size = 10\n",
    "\n",
    "# show a batch before and after denorm\n",
    "test_data_iter = iter(pkmn_dataloader)\n",
    "test_images, test_labels = next(test_data_iter)\n",
    "\n",
    "print(\"length of dataset (number of steps) is: {}, total size is: {}\".format(len(pkmn_dataloader), len(pkmn_dataloader)*batch_size))\n",
    "\n",
    "if show_preview:\n",
    "  show_tensor_images(test_images[0:test_size], num_images = test_size, size = (3,64,64), denorm_transform = None)\n",
    "  show_tensor_images(test_images[0:test_size], num_images = test_size, size = (3,64,64), denorm_transform = denorm_transform)\n",
    "\n",
    "if use_reduced_types:\n",
    "  valid_types = REDUCED_PKMN_TYPES\n",
    "  class_idx_to_type = CLASS_IDX_2_PKMN_TYPE_REDUCED\n",
    "else:\n",
    "  valid_types = PKMN_TYPES\n",
    "  class_idx_to_type = CLASS_IDX_2_PKMN_TYPE\n",
    "  \n",
    "num_pkmn_types = len(valid_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a1243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the generator/discriminator and use them\n",
    "# layer initialization for Generator and Discriminator (for Conv2d and ConvTranpose2d)\n",
    "\n",
    "#gen = DCGeneratorConditionalLarge(z_dim = z_dim, hidden_dim = hidden_dim_gen, output_dim = 96, use_class_embed = False, class_embed_size = 16).to(device)\n",
    "gen = UNetConditional(z_dim = z_dim, hidden_channels= hidden_dim_gen, input_dim = 64, use_dropout = False, dropout_prob = 0.1).to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=gen_lr, betas=(beta_1, beta_2))\n",
    "disc = DCDiscriminatorConditional(hidden_dim = hidden_dim_disc, class_embed_size=disc_class_embed_size,\n",
    "                                early_dropout=0.5, mid_dropout = 0.5, late_dropout = 0.5).to(device)\n",
    "# DiscriminatorPatchGANConditional(hidden_channels = hidden_dim_disc, use_dropout = True, dropout_prob = 0.5).to(device) \n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=disc_lr, betas=(beta_1, beta_2))\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "gen = gen.apply(weights_init)\n",
    "disc = disc.apply(weights_init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59280606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "cur_step = 0\n",
    "generator_losses = []\n",
    "discriminator_losses = []\n",
    "discriminator_fake_preds = [] # median value of P(real) the discriminator predicts on the fake images (per batch)\n",
    "discriminator_real_preds = [] # median value of P(real) the discriminator predicts on the real images (per batch)\n",
    "sigmoid_function = nn.Sigmoid() # use this if you have logit outputs\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Dataloader returns the (real_images, labels)\n",
    "    for real, true_labels in tqdm(pkmn_dataloader):\n",
    "        cur_batch_size = len(real)\n",
    "        real = real.to(device)\n",
    "        true_labels = true_labels.to(device)\n",
    "        \n",
    "        mean_iteration_discriminator_loss = 0\n",
    "        for _ in range(disc_repeats):\n",
    "            ### Update discriminator ###\n",
    "            disc_opt.zero_grad()\n",
    "            fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
    "            fake = gen(fake_noise, true_labels)\n",
    "            \n",
    "            disc_fake_pred = disc(fake.detach(), true_labels)\n",
    "            disc_real_pred = disc(real, true_labels)\n",
    "\n",
    "            \n",
    "            if use_wgan_loss:\n",
    "              epsilon = torch.rand(len(real), 1, 1, 1, device=device, requires_grad=True)\n",
    "              gradient = get_gradient(disc, real, true_labels, fake.detach(), epsilon)\n",
    "              gp = gradient_penalty(gradient)\n",
    "              # how should we track these two relative losses ?\n",
    "              disc_loss = disc_loss_func(disc_fake_pred, disc_real_pred, gp, c_lambda)              \n",
    "\n",
    "            else:\n",
    "              # compute discriminator loss normally\n",
    "              disc_loss = disc_loss_func(disc_fake_pred, disc_real_pred, device)\n",
    "            \n",
    "            # Keep track of the average discriminator loss in this batch\n",
    "            mean_iteration_discriminator_loss += disc_loss.item() / disc_repeats\n",
    "            \n",
    "            # Update gradients\n",
    "            # when using WGAN, we have retain_graph = True, but it probably takes longer\n",
    "            disc_loss.backward(retain_graph=use_wgan_loss)\n",
    "            \n",
    "            # Update optimizer\n",
    "            disc_opt.step()\n",
    "            \n",
    "        discriminator_losses += [mean_iteration_discriminator_loss]\n",
    "        # notice this only takes the last one from the iteration (if you run the discriminator multiple times)\n",
    "        # use a Sigmoid here to go from logits back into the P(real) space\n",
    "        discriminator_fake_preds += [torch.mean(disc_fake_pred).detach()]\n",
    "        discriminator_real_preds += [torch.mean(disc_real_pred).detach()]\n",
    "\n",
    "        ### Update generator ###\n",
    "        mean_iteration_gen_loss = 0\n",
    "        for _ in range(gen_repeats):\n",
    "          gen_opt.zero_grad()\n",
    "          fake_noise_2 = get_noise(cur_batch_size, z_dim, device=device)\n",
    "          fake_2 = gen(fake_noise_2, true_labels)\n",
    "          disc_fake_pred = disc(fake_2, true_labels)\n",
    "\n",
    "          # compute gen loss\n",
    "          gen_loss = gen_loss_func(disc_fake_pred, device)\n",
    "          \n",
    "          mean_iteration_gen_loss += gen_loss.item() / gen_repeats\n",
    "          \n",
    "          gen_loss.backward()\n",
    "\n",
    "          # Update the weights\n",
    "          gen_opt.step()\n",
    "\n",
    "        # Keep track of the average generator loss\n",
    "        generator_losses += [mean_iteration_gen_loss]\n",
    "        \n",
    "        ### Visualization code ###\n",
    "        if cur_step % display_step == 0 and cur_step > 0:\n",
    "            gen_mean = sum(generator_losses[-display_step:]) / display_step\n",
    "            disc_mean = sum(discriminator_losses[-display_step:]) / display_step\n",
    "            # maybe print out the last values here ? To see how stable it is overtime ? These all seem to be very close to 0.5 / 1\n",
    "            disc_prediction_real = sum(discriminator_real_preds[-display_step:]) / display_step\n",
    "            disc_prediction_fake = sum(discriminator_fake_preds[-display_step:]) / display_step\n",
    "            print(f\"Step {cur_step}: Epoch: {epoch}: Generator loss: {gen_mean}, discriminator loss: {disc_mean} mean disc pred on real images: {disc_prediction_real}, fake images: {disc_prediction_fake}\")\n",
    "            show_tensor_images(fake[0:imgs_to_display], imgs_to_display, size = (3,64,64), denorm_transform = denorm_transform)\n",
    "            show_tensor_images(real[0:imgs_to_display], imgs_to_display, size = (3,64,64), denorm_transform = denorm_transform)\n",
    "            \n",
    "            ground_truth_types = [class_idx_to_type[class_idx] for class_idx in true_labels[0:imgs_to_display].cpu().numpy()]\n",
    "            print(\"Pokemon types we are trying to generate are: {} \\n    \\t \\t \\t \\t \\t {}\".format(ground_truth_types[0:5], ground_truth_types[5:]))\n",
    "            \n",
    "            step_bins = 20\n",
    "            \n",
    "            # todo: add proper labels to this plot\n",
    "            num_examples = (len(generator_losses) // step_bins) * step_bins\n",
    "            plt.plot(\n",
    "                range(num_examples // step_bins), \n",
    "                torch.Tensor(generator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                label=\"Generator Loss\"\n",
    "            )\n",
    "            plt.plot(\n",
    "                range(num_examples // step_bins), \n",
    "                torch.Tensor(discriminator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                label=\"discriminator Loss\"\n",
    "            )\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        \n",
    "        # increase the current step (ie. one batch)\n",
    "        cur_step += 1\n",
    "        \n",
    "    if periodic_saving and epoch % epoch_save_step == 0 and epoch_save_step > 0:\n",
    "      outfile_name = \"{}_{}.pt\".format(save_prefix, cur_step)\n",
    "      print(\"===== Saving intermediate model with name {} ! ====\".format(outfile_name))\n",
    "      save_model(gen, outfile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f627c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "\n",
    "out_file = \"second_gan_with_standard_dcgan_arch_after_149epochs.pt\"\n",
    "  \n",
    "save_model(gen, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da493fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model for inference and generate some random classes\n",
    "\n",
    "gen.load_state_dict(torch.load(\"{}\".format(out_file)))\n",
    "\n",
    "# Performing inference - actually, maybe I ran some other cell after this so it's not really well defined\n",
    "num_samples = 10\n",
    "\n",
    "sample_vector = get_noise(num_samples, z_dim, device)\n",
    "random_classes = torch.randint(low = 0, high = num_pkmn_types, size = (num_samples,)).to(device)\n",
    "\n",
    "fake_images = gen(sample_vector, random_classes)\n",
    "\n",
    "output_size = gen.output_dim\n",
    "# + 0.9\n",
    "show_tensor_images(fake_images, num_images=num_samples, size=(1,256, 256), use_uniform_transform = True, denorm_transform = None)\n",
    "\n",
    "\n",
    "pkmn_classes = [class_idx_to_type[class_idx] for class_idx in random_classes.cpu().numpy()]\n",
    "print(\"Pokemon types we are trying to generate are: {} \\n    \\t \\t \\t \\t \\t {}\".format(pkmn_classes[0:5], pkmn_classes[5:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f9caf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples of a specific type from the model\n",
    "target_type = \"Fire\"\n",
    "class_idx = valid_types.index(target_type)\n",
    "\n",
    "class_tiled = torch.from_numpy(np.array([class_idx] * num_samples))\n",
    "\n",
    "sample_vector = get_noise(num_samples, z_dim, device)\n",
    "classes = class_tiled.to(device)\n",
    "\n",
    "fake_images = gen(sample_vector, classes)\n",
    "\n",
    "output_size = gen.output_dim\n",
    "# + 0.9\n",
    "show_tensor_images(fake_images, num_images=num_samples, size=(1,256, 256), use_uniform_transform = True, denorm_transform = None)\n",
    "\n",
    "\n",
    "pkmn_classes = [class_idx_to_type[class_idx] for class_idx in classes.cpu().numpy()]\n",
    "print(\"Pokemon types we are trying to generate are: {} \\n    \\t \\t \\t \\t \\t {}\".format(pkmn_classes[0:5], pkmn_classes[5:]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
